
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Handling Missing Values &#8212; 𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../_static/pone.0237978.g001.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Backpropagation on DAGs" href="backpropagation.html" />
    <link rel="prev" title="Hyperparameter Optimization using Optuna" href="optuna.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pone.0237978.g001.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MLOPS ZOOMCAMP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/01-intro/notes.html">
   Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/02-mlflow/notes.html">
   Experiment Tracking and Model Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/03-prefect/notes.html">
   Orchestration and ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/04-deployment/notes.html">
   Model Deployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/05-monitoring/notes.html">
   Model Monitoring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/06-best-practices/notes.html">
   Best practices
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODEL DEPLOYMENT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/production-code.html">
   Packaging Production Code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/model-serving-api.html">
   Prediction Serving API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/docker.html">
   Containerization with Docker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/cicd-pipelines.html">
   Continuous Integration and Deployment Pipelines
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FUNDAMENTALS
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pipelines.html">
   Modelling with Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="blending-stacking.html">
   Blending and Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="optuna.html">
   Hyperparameter Optimization using Optuna
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Handling Missing Values
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="backpropagation.html">
   Backpropagation on DAGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/01-tensorflow-nn.html">
   TensorFlow Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/02-tensorflow-mechanics.html">
   Mechanics of TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/03-tensorflow-activations.html">
   Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/04-tensorflow-optim-init.html">
   Initialization and Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/05-tensorflow-cnn.html">
   Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tensorflow/06-tensorflow-rnns.html">
   Recurrent Neural Networks
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/fundamentals/missing.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/particle1331/inefficient-networks"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/particle1331/inefficient-networks/issues/new?title=Issue%20on%20page%20%2Fnotebooks/fundamentals/missing.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-are-there-missing-values">
   Why are there missing values?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-values-per-feature">
     Missing values per feature
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-values-per-observation">
     Missing values per observation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation-between-missing-features">
     Correlation between missing features
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics-of-missing-value-imputation">
   Basics of missing value imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-value-indicators">
     Missing value indicators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-target-using-missing-value-indicators">
     Predicting target using missing value indicators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basic-imputation-techniques">
     Basic imputation techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-series-data">
   Time-series data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-based-imputation">
   Model-based imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simple-imputation">
     Simple imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iterative-imputation">
     Iterative imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nearest-neighbors">
     Nearest neighbors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xgboost-imputer">
     XGBoost Imputer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-imputer-to-choose">
   What imputer to choose?
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Handling Missing Values</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#why-are-there-missing-values">
   Why are there missing values?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-values-per-feature">
     Missing values per feature
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-values-per-observation">
     Missing values per observation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation-between-missing-features">
     Correlation between missing features
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#basics-of-missing-value-imputation">
   Basics of missing value imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#missing-value-indicators">
     Missing value indicators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#predicting-target-using-missing-value-indicators">
     Predicting target using missing value indicators
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#basic-imputation-techniques">
     Basic imputation techniques
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#time-series-data">
   Time-series data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-based-imputation">
   Model-based imputation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#simple-imputation">
     Simple imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#iterative-imputation">
     Iterative imputation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nearest-neighbors">
     Nearest neighbors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#xgboost-imputer">
     XGBoost Imputer
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-imputer-to-choose">
   What imputer to choose?
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="handling-missing-values">
<h1>Handling Missing Values<a class="headerlink" href="#handling-missing-values" title="Permalink to this headline">¶</a></h1>
<p><img alt="Status" src="https://img.shields.io/static/v1.svg?label=Status&amp;message=Finished&amp;color=brightgreen" />
<a class="reference external" href="https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/fundamentals/missing.ipynb"><img alt="Source" src="https://img.shields.io/static/v1.svg?label=GitHub&amp;message=Source&amp;color=181717&amp;logo=GitHub" /></a>
<a class="reference external" href="https://github.com/particle1331/inefficient-networks"><img alt="Stars" src="https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social" /></a></p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>𝗔𝘁𝘁𝗿𝗶𝗯𝘂𝘁𝗶𝗼𝗻: Based on Handling Missing Values by Kaggle Grandmaster Rob Mulla.
</pre></div>
</div>
<hr class="docutils" />
<p><sup></sup></p>
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, we will discuss some techniques that can be used to deal with <strong>missing values</strong> in <strong>tabular data</strong>. We will go from most basic to most complicated: from using pandas <code class="docutils literal notranslate"><span class="pre">fillna()</span></code> method to training models for filling in missing data.</p>
<p>Keep in mind that the complexity of the method is not correlated with better performance. Always test everything in your cross-validation scheme, and choose the best method, not necessarily what is the most complicated.</p>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">from</span> <span class="nn">matplotlib_inline</span> <span class="kn">import</span> <span class="n">backend_inline</span>
<span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Downloading the competition dataset:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">COMPETITION</span><span class="o">=</span><span class="s2">&quot;song-popularity-prediction&quot;</span>
<span class="nv">DATA_DIR</span><span class="o">=</span>./data
mkdir <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>
kaggle competitions download -c <span class="si">${</span><span class="nv">COMPETITION</span><span class="si">}</span> -p <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>
unzip <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">COMPETITION</span><span class="si">}</span>.zip -d <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">COMPETITION</span><span class="si">}</span> &gt; /dev/null
rm <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">COMPETITION</span><span class="si">}</span>.zip
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Downloading song-popularity-prediction.zip to ./data
 96%|████████████████████████████████████▎ | 4.00M/4.18M [00:01&lt;00:00, 3.01MB/s]
100%|██████████████████████████████████████| 4.18M/4.18M [00:01&lt;00:00, 3.00MB/s]
</pre></div>
</div>
<p>Loading the dataset and taking a look at the unprocessed data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">DATASET_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;./data/song-popularity-prediction&quot;</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATASET_PATH</span> <span class="o">/</span> <span class="s2">&quot;train.csv&quot;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATASET_PATH</span> <span class="o">/</span>  <span class="s2">&quot;test.csv&quot;</span><span class="p">)</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATASET_PATH</span> <span class="o">/</span> <span class="s2">&quot;sample_submission.csv&quot;</span><span class="p">)</span>

<span class="c1"># Add indicator column so we can combine all data in a single df</span>
<span class="n">train</span><span class="p">[</span><span class="s2">&quot;is_train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">test</span><span class="p">[</span><span class="s2">&quot;is_train&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">tt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">])</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(40000, 16) (10000, 15) (50000, 16)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>song_duration_ms</th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>audio_mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>audio_valence</th>
      <th>song_popularity</th>
      <th>is_train</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>212990.0</td>
      <td>0.642286</td>
      <td>0.856520</td>
      <td>0.707073</td>
      <td>0.002001</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>-5.619088</td>
      <td>0</td>
      <td>0.082570</td>
      <td>158.386236</td>
      <td>4</td>
      <td>0.734642</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>NaN</td>
      <td>0.054866</td>
      <td>0.733289</td>
      <td>0.835545</td>
      <td>0.000996</td>
      <td>8.0</td>
      <td>0.436428</td>
      <td>-5.236965</td>
      <td>1</td>
      <td>0.127358</td>
      <td>102.752988</td>
      <td>3</td>
      <td>0.711531</td>
      <td>1.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>193213.0</td>
      <td>NaN</td>
      <td>0.188387</td>
      <td>0.783524</td>
      <td>-0.002694</td>
      <td>5.0</td>
      <td>0.170499</td>
      <td>-4.951759</td>
      <td>0</td>
      <td>0.052282</td>
      <td>178.685791</td>
      <td>3</td>
      <td>0.425536</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>249893.0</td>
      <td>0.488660</td>
      <td>0.585234</td>
      <td>0.552685</td>
      <td>0.000608</td>
      <td>0.0</td>
      <td>0.094805</td>
      <td>-7.893694</td>
      <td>0</td>
      <td>0.035618</td>
      <td>128.715630</td>
      <td>3</td>
      <td>0.453597</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>165969.0</td>
      <td>0.493017</td>
      <td>NaN</td>
      <td>0.740982</td>
      <td>0.002033</td>
      <td>10.0</td>
      <td>0.094891</td>
      <td>-2.684095</td>
      <td>0</td>
      <td>0.050746</td>
      <td>121.928157</td>
      <td>4</td>
      <td>0.741311</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="why-are-there-missing-values">
<h2>Why are there missing values?<a class="headerlink" href="#why-are-there-missing-values" title="Permalink to this headline">¶</a></h2>
<p>Before starting with missing value imputation, we should ask why missing values are there. It could be that values are randomly missing, or the fact that they are missing can be used as a feature to improve your models. You need to understand why you have missing values before deciding on the approach for dealing with them. For example, we can have the following causes of missing data:</p>
<ul class="simple">
<li><p>Sensor data where the sensor went offline.</p></li>
<li><p>Survey data where some questions were not answered.</p></li>
<li><p>A Kaggle competition where the host wants to make the problem hard.</p></li>
</ul>
<div class="section" id="missing-values-per-feature">
<h3>Missing values per feature<a class="headerlink" href="#missing-values-per-feature" title="Permalink to this headline">¶</a></h3>
<p>What are the counts of missing values in train vs. test set?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">train</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">test</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">n_counts</span> <span class="o">=</span> <span class="n">n_counts</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;train_missing&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;test_missing&quot;</span><span class="p">})</span>
<span class="n">n_counts</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;(train_missing &gt; 0) or (test_missing &gt; 0)&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;train_missing&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;barh&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Percentage of missing values per feature&quot;</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">fancybox</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/missing_14_0.svg" src="../../_images/missing_14_0.svg" /></div>
</div>
<p>Note that percentage of missing values are all around 10%. It’s likely that these are dropped on purpose. Or there are systematic reasons why these values are missing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">na_cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">n_counts</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;(train_missing &gt; 0) or (test_missing &gt; 0)&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">na_cols</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;song_duration_ms&#39;,
 &#39;acousticness&#39;,
 &#39;danceability&#39;,
 &#39;energy&#39;,
 &#39;instrumentalness&#39;,
 &#39;key&#39;,
 &#39;liveness&#39;,
 &#39;loudness&#39;]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="missing-values-per-observation">
<h3>Missing values per observation<a class="headerlink" href="#missing-values-per-observation" title="Permalink to this headline">¶</a></h3>
<p>How many missing values per observation?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="p">[</span><span class="s2">&quot;n_missing&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="n">na_cols</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_train == True&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">n_missing</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test_hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_train == False&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">n_missing</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_hist</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">train_hist</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">test_hist</span><span class="p">,</span>  <span class="n">width</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution of number of missing values per observation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/missing_19_0.svg" src="../../_images/missing_19_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;n_missing == 6&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>song_duration_ms</th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>audio_mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>audio_valence</th>
      <th>song_popularity</th>
      <th>is_train</th>
      <th>n_missing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>13457</th>
      <td>13457</td>
      <td>176401.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.833408</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>0.052580</td>
      <td>142.802779</td>
      <td>3</td>
      <td>0.546615</td>
      <td>0.0</td>
      <td>True</td>
      <td>6</td>
    </tr>
    <tr>
      <th>19697</th>
      <td>19697</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.003014</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-10.708472</td>
      <td>0</td>
      <td>0.035591</td>
      <td>95.181833</td>
      <td>3</td>
      <td>0.483101</td>
      <td>0.0</td>
      <td>True</td>
      <td>6</td>
    </tr>
    <tr>
      <th>48594</th>
      <td>8594</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.344299</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1</td>
      <td>0.035495</td>
      <td>151.125383</td>
      <td>4</td>
      <td>0.463903</td>
      <td>NaN</td>
      <td>False</td>
      <td>6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Samples with high number of missing values will be difficult to impute. We usually drop these examples as they may degrade the model.</p>
</div>
<div class="section" id="correlation-between-missing-features">
<h3>Correlation between missing features<a class="headerlink" href="#correlation-between-missing-features" title="Permalink to this headline">¶</a></h3>
<p>We want to know whether the missing values in one feature implies missing values in another feature, and vice-versa. Note that Pearson correlation only works well for continuous features (not binary indicators). Instead we will use permutation testing where we compute the original <a class="reference external" href="https://en.wikipedia.org/wiki/Hamming_distance">Hamming distance</a> between two missing value indicators, then compute the Hamming distance when the other indicator is shuffled or permuted. We expect almost zero change if the missing indicators are not correlated in any way, and positive change otherwise (e.g. for diagonal entries).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>


<span class="k">def</span> <span class="nf">compute_importance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">):</span>
    <span class="c1"># Original Hamming distance</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="n">na_cols</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span>
    <span class="n">dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;hamming&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1"># Get off-diag entry (2x2 symm, zero diag).</span>

    <span class="c1"># &quot;Permuted&quot; Hamming distance</span>
    <span class="n">columns</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">columns</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">permuted_dist</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">columns</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;hamming&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">permuted_dist</span> <span class="o">-</span> <span class="n">dist</span>


<span class="n">permutation</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">na_cols</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">na_cols</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">na_cols</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">na_cols</span><span class="p">)):</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">compute_importance</span><span class="p">(</span><span class="n">na_cols</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">na_cols</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
        <span class="n">permutation</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">na_cols</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">na_cols</span><span class="p">[</span><span class="n">j</span><span class="p">]]</span> <span class="o">=</span> <span class="n">score</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">permutation</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;Blues&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Permutation test&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/missing_24_0.svg" src="../../_images/missing_24_0.svg" /></div>
</div>
</div>
</div>
<div class="section" id="basics-of-missing-value-imputation">
<h2>Basics of missing value imputation<a class="headerlink" href="#basics-of-missing-value-imputation" title="Permalink to this headline">¶</a></h2>
<p>This section outlines some of the first things to consider when handling missing data.</p>
<div class="section" id="missing-value-indicators">
<h3>Missing value indicators<a class="headerlink" href="#missing-value-indicators" title="Permalink to this headline">¶</a></h3>
<p>Adding a missing value indicator for each feature. If missing data does not occur completely at random, the <code class="docutils literal notranslate"><span class="pre">&quot;missing&quot;</span></code> label itself should have information. So adding missing flags for some features can improve model performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create indicator df</span>
<span class="n">tt_missing_tag_df</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="n">na_cols</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
<span class="n">tt_missing_tag_df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">_missing&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tt_missing_tag_df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

<span class="c1"># Concat to original df</span>
<span class="n">tt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">tt</span><span class="p">,</span> <span class="n">tt_missing_tag_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="predicting-target-using-missing-value-indicators">
<h3>Predicting target using missing value indicators<a class="headerlink" href="#predicting-target-using-missing-value-indicators" title="Permalink to this headline">¶</a></h3>
<p>Here we look at the degree by which the presence of missing values is predictive of the target class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_train == True&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">song_popularity</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0    25424
1.0    14576
Name: song_popularity, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># StratifiedKFold by default</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_train == 1&quot;</span><span class="p">)[[</span><span class="n">col</span><span class="o">+</span><span class="s2">&quot;_missing&quot;</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">na_cols</span><span class="p">]]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_train == 1&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">song_popularity</span>

<span class="c1"># Fit model + predict</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ROC-AUC:&quot;</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">preds</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ROC-AUC: 0.49278982302088525
</pre></div>
</div>
</div>
</div>
<p>This shows that missing indicators by themselves are not predictive of the target.</p>
</div>
<div class="section" id="basic-imputation-techniques">
<h3>Basic imputation techniques<a class="headerlink" href="#basic-imputation-techniques" title="Permalink to this headline">¶</a></h3>
<p><strong>Do nothing.</strong> Tree-based models like LightGBM and XGBoost <a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html">can work with missing values</a>. Other types of regression or neural networks will require some sort of imputation. Thus, one way to handle missing values is to simply use models that can treat missing values as features without any preprocessing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="nn">lgb</span>

<span class="c1"># use_missing=True (default) or zero_as_missing=False (convert NA to 0) are params that can be used</span>
<span class="n">lgbm_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;objective&#39;</span><span class="p">:</span> <span class="s1">&#39;regression&#39;</span><span class="p">,</span>
    <span class="s1">&#39;metric&#39;</span><span class="p">:</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span>
    <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;boost_from_average&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">&#39;min_data&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;num_leaves&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;min_data_in_bin&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">&#39;use_missing&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">&#39;zero_as_missing&#39;</span><span class="p">:</span> <span class="kc">True</span>
<span class="p">}</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">lgbm_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Drop them.</strong> Another technique is to simply drop observations with missing features. This  doesn’t work on the test set since we have to somehow impute missing values to make a prediction. We can also drop whole columns. But this leaves us less features to work with during modelling.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dropping observations</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># We can also drop on particular features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;song_duration_ms&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(50000, 33) (17259, 33)
(50000, 33) (44942, 33)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dropping whole features</span>
<span class="n">tt</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((50000, 33), (50000, 24))
</pre></div>
</div>
</div>
</div>
<p><strong>Pandas imputation.</strong> The Pandas library offer table-based functionalities for dealing with missing data. For instance, we can use Pandas <code class="docutils literal notranslate"><span class="pre">.fillna</span></code> as an easy way to fill missing values with arbitrary values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fill with a default value</span>
<span class="n">tt</span><span class="p">[</span><span class="s1">&#39;song_duration_ms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">999</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    212990.0
1      -999.0
2    193213.0
3    249893.0
4    165969.0
Name: song_duration_ms, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>For categorical variables, instead of the mean or median, we can use the most frequent value as <code class="docutils literal notranslate"><span class="pre">fill_value</span></code>.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Impute with mean (fixed)</span>
<span class="n">fill_value</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="s2">&quot;song_duration_ms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="c1"># or median</span>
<span class="n">tt</span><span class="p">[</span><span class="s2">&quot;song_duration_ms_mean_imp&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="s2">&quot;song_duration_ms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">fill_value</span><span class="p">)</span>

<span class="c1"># Printing</span>
<span class="n">tt</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">tt</span><span class="p">[</span><span class="s1">&#39;song_duration_ms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()][[</span><span class="s2">&quot;song_duration_ms&quot;</span><span class="p">,</span> <span class="s2">&quot;song_duration_ms_mean_imp&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_duration_ms</th>
      <th>song_duration_ms_mean_imp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>193150.809021</td>
    </tr>
    <tr>
      <th>13</th>
      <td>NaN</td>
      <td>193150.809021</td>
    </tr>
    <tr>
      <th>14</th>
      <td>NaN</td>
      <td>193150.809021</td>
    </tr>
    <tr>
      <th>15</th>
      <td>NaN</td>
      <td>193150.809021</td>
    </tr>
    <tr>
      <th>28</th>
      <td>NaN</td>
      <td>193150.809021</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Filling based on feature value.</strong> Here we impute using the average value of a feature over a group based on another feature. As an example we will use the <code class="docutils literal notranslate"><span class="pre">audio_mode</span></code> feature to group observations, where we will base our mean imputation for the <code class="docutils literal notranslate"><span class="pre">song_duration</span></code> feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sd_mean_map</span> <span class="o">=</span> <span class="n">tt</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;audio_mode&quot;</span><span class="p">)[</span><span class="s2">&quot;song_duration_ms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
<span class="n">sd_mean_map</span> <span class="c1"># song_duration mean per audio mode value.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{0: 193860.63699819762, 1: 191649.42961114578}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sd_mean_series</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="s1">&#39;audio_mode&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">sd_mean_map</span><span class="p">)</span> <span class="c1"># imputer if missing</span>
<span class="n">tt</span><span class="p">[</span><span class="s2">&quot;song_duration_ms_mean_audio_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tt</span><span class="p">[</span><span class="s2">&quot;song_duration_ms&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">sd_mean_series</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check for observations with missing <code class="docutils literal notranslate"><span class="pre">song_duration</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tt</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;song_duration_ms_missing == True&#39;</span><span class="p">)[[</span><span class="s1">&#39;audio_mode&#39;</span><span class="p">,</span><span class="s1">&#39;song_duration_ms_mean_audio_mode&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>audio_mode</th>
      <th>song_duration_ms_mean_audio_mode</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>191649.429611</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>193860.636998</td>
    </tr>
    <tr>
      <th>14</th>
      <td>0</td>
      <td>193860.636998</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0</td>
      <td>193860.636998</td>
    </tr>
    <tr>
      <th>28</th>
      <td>0</td>
      <td>193860.636998</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="time-series-data">
<h2>Time-series data<a class="headerlink" href="#time-series-data" title="Permalink to this headline">¶</a></h2>
<p>For time-series data, we can fill with the previous or next value in the column. Make sure that the data has been sorted before making this imputation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">ts_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span>

<span class="c1"># Randomly drop data</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Fill with different methods</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_ffill&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">ffill</span><span class="p">()</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_bfill&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">bfill</span><span class="p">()</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_mfill&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_ffill&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_bfill&quot;</span><span class="p">])</span>
<span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_mean_fill&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">ffill</span></code> pushes previous data to missing data, while <code class="docutils literal notranslate"><span class="pre">bfill</span></code> pulls next future data to missing data. Filling with the average of the two smooths the curve out as shown above. Also, note that the mean of the data is zero, since the sine curve completes two rotations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ts_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;data_missing&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;.-&quot;</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Time Series Imputation&#39;</span><span class="p">)</span>

<span class="c1"># Plot mean of data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">ts_data</span><span class="p">[</span><span class="s2">&quot;data_missing&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># Plot data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts_data</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C4&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts_data</span><span class="o">.</span><span class="n">data_missing</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;solid&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C4&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">ts_data</span><span class="o">.</span><span class="n">data_missing</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C4&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/missing_54_0.svg" src="../../_images/missing_54_0.svg" /></div>
</div>
</div>
<div class="section" id="model-based-imputation">
<h2>Model-based imputation<a class="headerlink" href="#model-based-imputation" title="Permalink to this headline">¶</a></h2>
<p>Model-based imputers train on the dataset to find the missing values to impute. We will look at imputers available in scikit-learn, then we will implement our own XGBoost imputer. First, we will use imputers in the scikit-learn library, then we will look at an XGBoost-based imputer. Using scikit-learn is nice because of the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> API. The imputer can also be part of a scikit-learn pipeline. Then, we implement XGBoost imputation which has been shown to have good performance in some Kaggle competitions.</p>
<div class="section" id="simple-imputation">
<h3>Simple imputation<a class="headerlink" href="#simple-imputation" title="Permalink to this headline">¶</a></h3>
<p>Simple imputation replaces missing values with feature-wise mean or median, or some constant. This is implemented in scikit-learn with the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"><code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code></a> transformer. This has the <code class="docutils literal notranslate"><span class="pre">add_indicator</span></code> argument for adding an indicator column which can help with models such as tree-based models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;song_duration_ms&quot;</span><span class="p">,</span>
    <span class="s2">&quot;acousticness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;danceability&quot;</span><span class="p">,</span>
    <span class="s2">&quot;energy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;instrumentalness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;key&quot;</span><span class="p">,</span>
    <span class="s2">&quot;liveness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;loudness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;audio_mode&quot;</span><span class="p">,</span>
    <span class="s2">&quot;speechiness&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tempo&quot;</span><span class="p">,</span>
    <span class="s2">&quot;time_signature&quot;</span><span class="p">,</span>
    <span class="s2">&quot;audio_valence&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Testing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="c1"># Initialize mean imputer. No need to add indicator when transforming.</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">add_indicator</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Fit + transform `song_duration`.</span>
<span class="n">train_column</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;song_duration_ms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_column</span><span class="p">)</span>

<span class="c1"># Looking at result:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mean:&quot;</span><span class="p">,</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;song_duration_ms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">train_column</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_column</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;transformed_data&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>mean: 193165.84757235576
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>data</th>
      <th>transformed_data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>212990.0</td>
      <td>212990.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>193165.847572</td>
    </tr>
    <tr>
      <th>2</th>
      <td>193213.0</td>
      <td>193213.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>249893.0</td>
      <td>249893.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165969.0</td>
      <td>165969.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">SimpleImputer</span></code> can be applied on the entire feature set to simultaneously fit on each column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fit / Transform on train, transform only on val / test</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">add_indicator</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">test_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>

<span class="c1"># Note that `transform` returns an array, so we have to reconstruct.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No. missing:&quot;</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_imputed</span><span class="p">)</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No. missing: 0
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_duration_ms</th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>audio_mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>audio_valence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>212990.000000</td>
      <td>0.642286</td>
      <td>0.856520</td>
      <td>0.707073</td>
      <td>0.002001</td>
      <td>10.0</td>
      <td>0.198514</td>
      <td>-5.619088</td>
      <td>0.0</td>
      <td>0.082570</td>
      <td>158.386236</td>
      <td>4.0</td>
      <td>0.734642</td>
    </tr>
    <tr>
      <th>1</th>
      <td>193165.847572</td>
      <td>0.054866</td>
      <td>0.733289</td>
      <td>0.835545</td>
      <td>0.000996</td>
      <td>8.0</td>
      <td>0.436428</td>
      <td>-5.236965</td>
      <td>1.0</td>
      <td>0.127358</td>
      <td>102.752988</td>
      <td>3.0</td>
      <td>0.711531</td>
    </tr>
    <tr>
      <th>2</th>
      <td>193213.000000</td>
      <td>0.276404</td>
      <td>0.188387</td>
      <td>0.783524</td>
      <td>-0.002694</td>
      <td>5.0</td>
      <td>0.170499</td>
      <td>-4.951759</td>
      <td>0.0</td>
      <td>0.052282</td>
      <td>178.685791</td>
      <td>3.0</td>
      <td>0.425536</td>
    </tr>
    <tr>
      <th>3</th>
      <td>249893.000000</td>
      <td>0.488660</td>
      <td>0.585234</td>
      <td>0.552685</td>
      <td>0.000608</td>
      <td>0.0</td>
      <td>0.094805</td>
      <td>-7.893694</td>
      <td>0.0</td>
      <td>0.035618</td>
      <td>128.715630</td>
      <td>3.0</td>
      <td>0.453597</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165969.000000</td>
      <td>0.493017</td>
      <td>0.570951</td>
      <td>0.740982</td>
      <td>0.002033</td>
      <td>10.0</td>
      <td>0.094891</td>
      <td>-2.684095</td>
      <td>0.0</td>
      <td>0.050746</td>
      <td>121.928157</td>
      <td>4.0</td>
      <td>0.741311</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For kaggle competition you can kind of cheat by fitting on all data</span>
<span class="n">tt_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>

<span class="n">tt_simple_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>
<span class="n">tt_simple_imputed</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>song_duration_ms</th>
      <th>acousticness</th>
      <th>danceability</th>
      <th>energy</th>
      <th>instrumentalness</th>
      <th>key</th>
      <th>liveness</th>
      <th>loudness</th>
      <th>audio_mode</th>
      <th>speechiness</th>
      <th>tempo</th>
      <th>time_signature</th>
      <th>audio_valence</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>212990.000000</td>
      <td>0.642286</td>
      <td>0.856520</td>
      <td>0.707073</td>
      <td>0.002001</td>
      <td>10.0</td>
      <td>0.198086</td>
      <td>-5.619088</td>
      <td>0.0</td>
      <td>0.082570</td>
      <td>158.386236</td>
      <td>4.0</td>
      <td>0.734642</td>
    </tr>
    <tr>
      <th>1</th>
      <td>193150.809021</td>
      <td>0.054866</td>
      <td>0.733289</td>
      <td>0.835545</td>
      <td>0.000996</td>
      <td>8.0</td>
      <td>0.436428</td>
      <td>-5.236965</td>
      <td>1.0</td>
      <td>0.127358</td>
      <td>102.752988</td>
      <td>3.0</td>
      <td>0.711531</td>
    </tr>
    <tr>
      <th>2</th>
      <td>193213.000000</td>
      <td>0.277183</td>
      <td>0.188387</td>
      <td>0.783524</td>
      <td>-0.002694</td>
      <td>5.0</td>
      <td>0.170499</td>
      <td>-4.951759</td>
      <td>0.0</td>
      <td>0.052282</td>
      <td>178.685791</td>
      <td>3.0</td>
      <td>0.425536</td>
    </tr>
    <tr>
      <th>3</th>
      <td>249893.000000</td>
      <td>0.488660</td>
      <td>0.585234</td>
      <td>0.552685</td>
      <td>0.000608</td>
      <td>0.0</td>
      <td>0.094805</td>
      <td>-7.893694</td>
      <td>0.0</td>
      <td>0.035618</td>
      <td>128.715630</td>
      <td>3.0</td>
      <td>0.453597</td>
    </tr>
    <tr>
      <th>4</th>
      <td>165969.000000</td>
      <td>0.493017</td>
      <td>0.570724</td>
      <td>0.740982</td>
      <td>0.002033</td>
      <td>10.0</td>
      <td>0.094891</td>
      <td>-2.684095</td>
      <td>0.0</td>
      <td>0.050746</td>
      <td>121.928157</td>
      <td>4.0</td>
      <td>0.741311</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
<div class="section" id="iterative-imputation">
<h3>Iterative imputation<a class="headerlink" href="#iterative-imputation" title="Permalink to this headline">¶</a></h3>
<p>In scikit-learn, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html"><code class="docutils literal notranslate"><span class="pre">IterativeImputer</span></code></a> is a multivariate imputer that estimates each feature from all the other features. This is a strategy for imputing missing values by modeling each feature with missing values as a function of other features in an iterative (“round-robin”) fashion that is controled by <code class="docutils literal notranslate"><span class="pre">max_iter=10</span></code>. Uses <a class="reference external" href="https://scikit-learn.org/stable/modules/linear_model.html#bayesian-ridge-regression"><code class="docutils literal notranslate"><span class="pre">BayesianRidge</span></code></a> as its default model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>  <span class="c1"># noqa</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
</pre></div>
</div>
</div>
</div>
<p>We want to fit and predict on all columns because the model is using all features to help fill the missing values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">it_imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">train_iter_imputed</span> <span class="o">=</span> <span class="n">it_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">test_iter_imputed</span> <span class="o">=</span> <span class="n">it_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">tt_iter_imputed</span> <span class="o">=</span> <span class="n">it_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>

<span class="c1"># Create train test imputed dataframe</span>
<span class="n">tt_iter_imputed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_iter_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 52.7 s, sys: 5.6 s, total: 58.3 s
Wall time: 9.23 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Save this off to use later</span>
<span class="n">tt_iter_imputed_df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="n">DATASET_PATH</span> <span class="o">/</span> <span class="s2">&quot;tt_iterative_imputed.parquet&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="nearest-neighbors">
<h3>Nearest neighbors<a class="headerlink" href="#nearest-neighbors" title="Permalink to this headline">¶</a></h3>
<p>In scikit-learn, <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html"><code class="docutils literal notranslate"><span class="pre">KNNImputer</span></code></a> uses a rows nearest neighbors to model each missing value in the dataset from the mean value from <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> nearest neighbors found in the training set. Here, two samples are close if the features that neither is missing are close. Note that this can be quite slow since it is based on KNN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">KNNImputer</span>
<span class="n">knn_imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_knn_imputed</span> <span class="o">=</span> <span class="n">knn_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">test_knn_imputed</span> <span class="o">=</span> <span class="n">knn_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">tt_knn_imputed</span> <span class="o">=</span> <span class="n">knn_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">tt_knn_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_knn_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>

<span class="c1"># Create KNN Train/Test imputed dataframe</span>
<span class="n">knn_imputed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_knn_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 3min 14s, sys: 3min 12s, total: 6min 27s
Wall time: 18min 17s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">knn_imputed_df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="xgboost-imputer">
<h3>XGBoost Imputer<a class="headerlink" href="#xgboost-imputer" title="Permalink to this headline">¶</a></h3>
<p>This is another model-based approach (like KNN and iterative imputation above) which here uses <strong>gradient boosting</strong>. The algorithm works as follows: if a feature <code class="docutils literal notranslate"><span class="pre">f</span></code> has missing values, create a regression (classification) model to predict non-missing values of <code class="docutils literal notranslate"><span class="pre">f</span></code> from all other features. The model predicts on the subset of examples with missing <code class="docutils literal notranslate"><span class="pre">f</span></code> as our imputation values. Then, perform this for all the feature columns with missing values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span><span class="p">,</span> <span class="n">XGBRegressor</span>

<span class="k">class</span> <span class="nc">XGBImputer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cat_features</span><span class="p">,</span> <span class="n">xgb_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cat_features</span> <span class="o">=</span> <span class="n">cat_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">imputers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xgb_params</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">xgb_params</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">xgb_params</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">null_feature</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">null_feature</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            
            <span class="c1"># Preparing the imputer train dataset</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">null_feature</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">null_feature</span><span class="p">][</span><span class="n">col</span><span class="p">]</span>
            <span class="n">y_train_min</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train_min</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">-</span> <span class="n">y_train_min</span> <span class="c1"># offset to [0, +∞)</span>

            <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cat_features</span><span class="p">:</span>
                <span class="n">imputer</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">xgb_params</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">imputer</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">xgb_params</span><span class="p">)</span>

            <span class="c1"># Fit xgboost predictor</span>
            <span class="n">imputer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">imputers</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">imputer</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">null_feature</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">null_feature</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">fill_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">imputers</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">null_feature</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">X</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">null_feature</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">fill_values</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">offsets</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">X</span>

    <span class="k">def</span> <span class="nf">fit_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Testing:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">cat_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;key&#39;</span><span class="p">,</span> <span class="s1">&#39;audio_mode&#39;</span><span class="p">,</span> <span class="s1">&#39;time_signature&#39;</span><span class="p">]</span>
<span class="n">xgb_imputer</span> <span class="o">=</span> <span class="n">XGBImputer</span><span class="p">(</span><span class="n">cat_features</span><span class="o">=</span><span class="n">cat_features</span><span class="p">)</span>

<span class="n">train_xgbimputed</span> <span class="o">=</span> <span class="n">xgb_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">test_xgbimputed</span> <span class="o">=</span> <span class="n">xgb_imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">tt_xgbimputed</span> <span class="o">=</span> <span class="n">xgb_imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">])</span>
<span class="n">tt_imputed</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_xgbimputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>

<span class="c1"># Create XGB train / test imputed dataframe</span>
<span class="n">xgb_imputed_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tt_imputed</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[17:14:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;multi:softprob&#39; was changed from &#39;merror&#39; to &#39;mlogloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior.
[17:15:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426411619/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;multi:softprob&#39; was changed from &#39;merror&#39; to &#39;mlogloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior.
CPU times: user 14min 3s, sys: 2min 41s, total: 16min 44s
Wall time: 2min 50s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgb_imputed_df</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the results of different imputation methods.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">knn_imputed_df</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;imputed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;KNN&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">xgb_imputed_df</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;imputed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;XGBoost&quot;</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tt</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">tt_simple_imputed</span><span class="o">.</span><span class="n">acousticness</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;imputed&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Mean&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/missing_81_0.svg" src="../../_images/missing_81_0.svg" /></div>
</div>
<p>KNN follows the existing distribution most closely, while XGBoost imputation allows for a little variation (which may be desirable). For the simple imputer, all imputed data concentrates on a single point which here is the mean of the known values. In general, its better to use median imputer for skewed distributions (a few extreme values can bias the mean).</p>
</div>
</div>
<div class="section" id="what-imputer-to-choose">
<h2>What imputer to choose?<a class="headerlink" href="#what-imputer-to-choose" title="Permalink to this headline">¶</a></h2>
<p>Test on your cross-validation folds! Always test everything in your cross-validation scheme and choose the best method. Not necessarily what you think is the most complicated. The philosophy is that since the dataset is too complex, there no straightforward way to know <em>a priori</em> which method will work best, so we take an experimental approach. GM Bojan Tunguz expresses this nicely in <a class="reference external" href="https://medium.com/&#64;tunguz/about-those-transformers-for-tabular-data-116c13c36a5c">his blog post</a> about <a class="reference external" href="https://keras.io/examples/structured_data/tabtransformer/">transformers for tabular data</a>:</p>
<blockquote>
<div><p>There is a tendency in certain parts of the ML world to equate technical virtuosity with the quality of ML modeling. Unfortunately, this ethos is especially prevelant (<em>sic</em>) in the cautting (<em>sic</em>) edge tech sector. It cannot be emphasized strongly enough that this is a misguided attitude at best, and can lead to downright inferior models […].</p>
</div></blockquote>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/fundamentals"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="optuna.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Hyperparameter Optimization using Optuna</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="backpropagation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Backpropagation on DAGs</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 𝗥𝗼𝗻 𝗠𝗲𝗱𝗶𝗻𝗮. Powered by <a href="https://jupyterbook.org">Jupyter Book</a>.<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>