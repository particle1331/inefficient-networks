
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Convolutional Neural Networks &#8212; 𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../_static/pone.0237978.g001.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Recurrent Neural Networks" href="06-tensorflow-rnns.html" />
    <link rel="prev" title="Initialization and Optimization" href="04-tensorflow-optim-init.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pone.0237978.g001.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">𝗜𝗻𝗲𝗳𝗳𝗶𝗰𝗶𝗲𝗻𝘁 𝗡𝗲𝘁𝘄𝗼𝗿𝗸𝘀</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MLOPS ZOOMCAMP
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/01-intro/notes.html">
   Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/02-mlflow/notes.html">
   Experiment Tracking and Model Management
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/03-prefect/notes.html">
   Orchestration and ML Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/04-deployment/notes.html">
   Model Deployment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/05-monitoring/notes.html">
   Model Monitoring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/06-best-practices/notes.html">
   Best practices
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  MODEL DEPLOYMENT
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/production-code.html">
   Packaging Production Code
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/model-serving-api.html">
   Prediction Serving API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/docker.html">
   Containerization with Docker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deployment/cicd-pipelines.html">
   Continuous Integration and Deployment Pipelines
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  FUNDAMENTALS
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../fundamentals/pipelines.html">
   Modelling with Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fundamentals/blending-stacking.html">
   Blending and Stacking
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fundamentals/optuna.html">
   Hyperparameter Optimization using Optuna
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../fundamentals/missing.html">
   Handling Missing Values
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DEEP LEARNING
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../fundamentals/backpropagation.html">
   Backpropagation on DAGs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="01-tensorflow-nn.html">
   TensorFlow Datasets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-tensorflow-mechanics.html">
   Mechanics of TensorFlow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-tensorflow-activations.html">
   Activation Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-tensorflow-optim-init.html">
   Initialization and Optimization
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-tensorflow-rnns.html">
   Recurrent Neural Networks
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/tensorflow/05-tensorflow-cnn.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/particle1331/inefficient-networks"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/particle1331/inefficient-networks/issues/new?title=Issue%20on%20page%20%2Fnotebooks/tensorflow/05-tensorflow-cnn.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolution-operation">
   Convolution operation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-layer">
     Convolutional layer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-visualization">
       Kernel visualization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implementation">
       Implementation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stride-and-padding">
     Stride and padding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#output-size">
     Output size
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downsampling">
     Downsampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementing-a-convnet">
   Implementing a convnet
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#network-structure">
     Network structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#effect-of-batch-normalization">
     Effect of Batch Normalization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-augmentation">
   Data augmentation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformations">
     Transformations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-the-augmented-dataset">
     Creating the augmented dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-average-pooling">
     Global average pooling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-training-and-results">
     Model training and results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#class-activation-maps">
   Class activation maps
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-learning">
   Transfer learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fine-tuning">
     Fine-tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mobilenetv2-architecture">
     MobileNetV2 architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization-layers-in-transfer-learning">
     Batch normalization layers in transfer learning
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Convolutional Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolution-operation">
   Convolution operation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-layer">
     Convolutional layer
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#kernel-visualization">
       Kernel visualization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#implementation">
       Implementation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stride-and-padding">
     Stride and padding
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#output-size">
     Output size
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#downsampling">
     Downsampling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#implementing-a-convnet">
   Implementing a convnet
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#network-structure">
     Network structure
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training">
     Training
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#effect-of-batch-normalization">
     Effect of Batch Normalization
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-augmentation">
   Data augmentation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transformations">
     Transformations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#creating-the-augmented-dataset">
     Creating the augmented dataset
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-average-pooling">
     Global average pooling
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-training-and-results">
     Model training and results
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#class-activation-maps">
   Class activation maps
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#transfer-learning">
   Transfer learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fine-tuning">
     Fine-tuning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#appendix">
   Appendix
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mobilenetv2-architecture">
     MobileNetV2 architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#batch-normalization-layers-in-transfer-learning">
     Batch normalization layers in transfer learning
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="convolutional-neural-networks">
<h1>Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="Permalink to this headline">¶</a></h1>
<p><img alt="Status" src="https://img.shields.io/static/v1.svg?label=Status&amp;message=Finished&amp;color=brightgreen" />
<a class="reference external" href="https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/tensorflow/05-tensorflow-cnn.ipynb"><img alt="Source" src="https://img.shields.io/static/v1.svg?label=GitHub&amp;message=Source&amp;color=181717&amp;logo=GitHub" /></a>
<a class="reference external" href="https://github.com/particle1331/inefficient-networks"><img alt="Stars" src="https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social" /></a></p>
<hr class="docutils" />
<div class="section" id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>In previous notebooks, we classified images by flattening them into long vectors as inputs to vanilla neural networks. This is unstatisfying since we are discarding important spatial information. For instance, we would get the same result if we permuted the pixels. Moreover, a layer that takes in a 256×256×3 RGB image and outputs an image of the same dimensionality requires around 39 billion parameters. This too much capacity for a single layer. And would take too much space in computer memory.</p>
<p>It would be nice if we can include our prior knowledge that pixels are spatially correlated in some way into the structure of our networks. For vision tasks, we can abstract away two desirable properties: <strong>translation invariance</strong> and <strong>locality</strong>. For our purposes, we take translation invariance to mean that a feature that is meaningful at a certain location should be equally meaningful for a model at another place in the image. Moreover, discriminative features for images typically exist only on localized regions, e.g. a dog’s nose or cat ears, so that looking at large regions of the image can potentially confuse the model. This also means that the resulting layer would require less weights since we assume prior structure in the images.</p>
<br><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">kr</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">cifar10</span>


<span class="kn">from</span> <span class="nn">matplotlib_inline</span> <span class="kn">import</span> <span class="n">backend_inline</span>
<span class="n">backend_inline</span><span class="o">.</span><span class="n">set_matplotlib_formats</span><span class="p">(</span><span class="s1">&#39;svg&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s2">&quot;once&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">DATASET_DIR</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;./data&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[PhysicalDevice(name=&#39;/physical_device:CPU:0&#39;, device_type=&#39;CPU&#39;), PhysicalDevice(name=&#39;/physical_device:GPU:0&#39;, device_type=&#39;GPU&#39;)]
2.8.0
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="convolution-operation">
<h2>Convolution operation<a class="headerlink" href="#convolution-operation" title="Permalink to this headline">¶</a></h2>
<p>The following discussion follows from <a class="reference external" href="https://deepimaging.github.io/lectures/lecture_9_intro_to_CNN%27s.pdf">this lecture</a> where the following image of a kitten is considered. Suppose we want to do linear classification where we have a matrix that linearly transforms an image of a cat to some 2-dimensional feature map. This matrix contains weights that encode pixel importance for each entry of the output feature map.</p>
<p>Notice that the two pixels indicated on the left image probably do not need to be mixed to figure out this is a cat. On the other hand, three nearby pixels on the right image can form a linear combination that can be useful for determining cat-like features. This means that pixels that are far away in the input have weights that cannot be nonzero at the same time. This results in a banded weight matrix.</p>
<div class="figure align-default" id="id13">
<a class="reference internal image-reference" href="../../_images/cat-conv.png"><img alt="../../_images/cat-conv.png" src="../../_images/cat-conv.png" style="width: 40em;" /></a>
<p class="caption"><span class="caption-number">Fig. 71 </span><span class="caption-text">Nearby pixels constitute meaningful features of images.</span><a class="headerlink" href="#id13" title="Permalink to this image">¶</a></p>
</div>
<p>Let <span class="math notranslate nohighlight">\(\mathbf X\)</span> be the input image and <span class="math notranslate nohighlight">\(\mathbf S\)</span> be the output feature map. Suppose <span class="math notranslate nohighlight">\({\mathsf n}^2 = |\mathbf X|\)</span> and <span class="math notranslate nohighlight">\({\mathsf m}^2 = |\mathbf S|.\)</span> Having a banded weight matrix reduces the size of the weight matrix from <span class="math notranslate nohighlight">\(\mathcal{O}(\mathsf{n}^2{\mathsf m}^2)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{O}(\mathsf k_h \mathsf k_w{\mathsf m}^2)\)</span> where a local region of <span class="math notranslate nohighlight">\(\mathsf k_h \times \mathsf k_w\)</span> pixels in the input are mixed. It makes sense to further constrain the weights in the local region to be equal througout the image since we want to capture translationally invariant features. This further reduces the number of weights to <span class="math notranslate nohighlight">\(\mathcal{O}(\mathsf k_h \mathsf k_w).\)</span> The resulting linear operation is called a <strong>convolution</strong> written in two spatial dimensions as:</p>
<div class="math notranslate nohighlight">
\[
\mathbf S_{ij} = (\mathbf X \circledast \mathbf W)_{ij} = \sum_{x = 0}^{{\mathsf k_h}-1} \sum_{y=0}^{{\mathsf k_w}-1} {\mathbf X}_{i + x, j + y} \, {\mathbf W}_{xy}.
\]</div>
<p>Observe that spatial ordering of the pixels in the input <span class="math notranslate nohighlight">\(\mathbf X\)</span> is somehow preserved in the output <span class="math notranslate nohighlight">\(\mathbf S.\)</span> This is nice since we want to preserve spatial information across a stack of convolution operations.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Figure source:<br>
<a class="reference external" href="https://deepimaging.github.io/lectures/lecture_9_intro_to_CNN%27s.pdf"><code class="docutils literal notranslate"><span class="pre">deepimaging.github.io</span></code></a></p>
</div>
<div class="figure align-default" id="id14">
<a class="reference internal image-reference" href="../../_images/conv-cat-99.png"><img alt="../../_images/conv-cat-99.png" src="../../_images/conv-cat-99.png" style="width: 30em;" /></a>
<p class="caption"><span class="caption-number">Fig. 72 </span><span class="caption-text">Banded Toeplitz matrix for classifying cats. The violet bars contain the same pixel values. For images, since we concatenate rows into a long vector, we will actually have multiple bands in the weight matrix.</span><a class="headerlink" href="#id14" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="convolutional-layer">
<h3>Convolutional layer<a class="headerlink" href="#convolutional-layer" title="Permalink to this headline">¶</a></h3>
<p>Replacing the dense operation with a convolution between the input and the weight tensors, we get the <strong>convolutional layer</strong> of a neural network. Note that we handle input and output channels as this allows for richer hidden representation, e.g. RGB images have three channels. The convolutional layer computes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
{\bar{\mathbf X}}_{ij,\, k} 
&amp;= \varphi\left({\boldsymbol u}_{k} + \sum_{c=0}^{{\mathsf c}_\text{in}-1} ({\mathbf X}_{[:,\, :,\, c]} \circledast {\mathbf K}_{[:,\,:,\, c,\,{k}]})_{ij} \right) \\
&amp;= \varphi\left({\boldsymbol u}_{k} + \sum_{c=0}^{{\mathsf c}_\text{in}-1}\sum_{x = 0}^{{\mathsf k}_h-1} \sum_{y=0}^{{\mathsf k}_w-1} {\mathbf X}_{i + x,\, j + y,\, c} \, {\mathbf K}_{xyc,{k}} \right) \\
\end{aligned}
\end{split}\]</div>
<p>for <span class="math notranslate nohighlight">\(k = 0, \ldots, {\mathsf c}_\text{out}-1\)</span>. The input and output tensors have the same dimensionality and semantic structure which makes sense since we want to stack convolutional layers in modular fashion. The shape of the weight tensor is <span class="math notranslate nohighlight">\(({\mathsf k}_h, {\mathsf k}_w, {\mathsf c}_\text{in}, {\mathsf c}_\text{out}).\)</span></p>
<div class="section" id="kernel-visualization">
<h4>Kernel visualization<a class="headerlink" href="#kernel-visualization" title="Permalink to this headline">¶</a></h4>
<p>Observe that the computation in convolutional layers is analogous to computation dense layers: with units that process images instead of numbers. Here the number of output channels correspond to layer width or the number of features of the hidden representation. This can be visualized as follows.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_conv_layer</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">conv</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Visualizing convolution kernels and output channels on a 3D image.&quot;&quot;&quot;</span>
    
    <span class="n">cmaps</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="s1">&#39;Greens&#39;</span><span class="p">,</span> <span class="s1">&#39;Blues&#39;</span><span class="p">]</span>
    <span class="n">S</span> <span class="o">=</span> <span class="n">conv</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">c_in</span>  <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">c_out</span> <span class="o">=</span> <span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Iterate over in channels</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">c_in</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">c_out</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:])</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_in</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;X(c=</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmaps</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>

    <span class="c1"># Iterate over out channels</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_out</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">S</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\bar{\mathrm</span><span class="si">{X}</span><span class="s2">}$&quot;</span> <span class="o">+</span> <span class="sa">f</span><span class="s1">&#39;(k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="c1"># Iterate over kernel filters</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_out</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_in</span><span class="p">):</span>
            <span class="n">K</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">][:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span> 
            <span class="n">ax</span><span class="p">[</span><span class="n">c</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;K(c=</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s1">, k=</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="n">kernel_size</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span> <span class="c1"># Frog?</span>
<span class="n">visualize_conv_layer</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">conv</span><span class="o">=</span><span class="n">conv</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-07-18 16:35:35.541537: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-07-18 16:35:35.544205: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -&gt; physical PluggableDevice (device: 0, name: METAL, pci bus id: &lt;undefined&gt;)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Metal device set to: Apple M1

systemMemory: 8.00 GB
maxCacheSize: 2.67 GB
</pre></div>
</div>
<img alt="../../_images/05-tensorflow-cnn_15_2.svg" src="../../_images/05-tensorflow-cnn_15_2.svg" /></div>
</div>
<p>Each kernel in entries <code class="docutils literal notranslate"><span class="pre">i,</span> <span class="pre">j</span> <span class="pre">&gt;</span> <span class="pre">0</span></code> combines column-wise with the inputs to compute <code class="docutils literal notranslate"><span class="pre">X(c=i)</span> <span class="pre">⊛</span> <span class="pre">K(c=i,</span> <span class="pre">k=j)</span></code>. The sum of these terms form the output map <code class="docutils literal notranslate"><span class="pre">X̅(k=j)</span></code> above. This looks quite like matrix multiplication which dense layers implement with numeric entries. But instead of products between numbers, here we have convolutions between matrices.</p>
</div>
<div class="section" id="implementation">
<h4>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h4>
<p>Here we check that the formula discussed above is the same formula implemented in the Keras <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> layer. Consistent with the above equation, this layer expects input images to have shape <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">H,</span> <span class="pre">W,</span> <span class="pre">c)</span></code> for a batch input of size <code class="docutils literal notranslate"><span class="pre">B</span></code> of <code class="docutils literal notranslate"><span class="pre">H</span> <span class="pre">×</span> <span class="pre">W</span></code> images with <code class="docutils literal notranslate"><span class="pre">c</span></code> channels. This is also expected the shape of output of a convolutional layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv2D</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implementing a 2D convolutional layer from scratch.&quot;&quot;&quot;</span>

    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">B</span><span class="p">,</span> <span class="n">H0</span><span class="p">,</span> <span class="n">W0</span><span class="p">,</span> <span class="n">c_in</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">H1</span> <span class="o">=</span> <span class="n">H0</span> <span class="o">-</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">W0</span> <span class="o">-</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">c_out</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

    <span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H1</span><span class="p">,</span> <span class="n">W1</span><span class="p">,</span> <span class="n">c_out</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">f</span> <span class="o">=</span> <span class="n">activation</span>

                    <span class="c1"># Perform 3D convolution (h, w, c_in) for each out channel</span>
                    <span class="n">S</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">u</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">K</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span><span class="n">j</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="p">:])</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">S</span>


<span class="n">X</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">/</span> <span class="mf">255.</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">conv2D</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input shape: &quot;</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (B, H_in,  W_in,  c_in)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output shape:&quot;</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (B, H_out, W_out, c_out)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Kernel shape:&quot;</span><span class="p">,</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (h, w, c_in, c_out)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Bias shape:  &quot;</span><span class="p">,</span> <span class="n">u</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>   <span class="c1"># (c_out,)</span>

<span class="c1"># Check if above formula agrees with TF implementation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean absolute error =&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">S</span> <span class="o">-</span> <span class="n">conv</span><span class="p">(</span><span class="n">X</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="c1"># Plotting the images obtained using the above formula</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Input shape:  (1, 32, 32, 3)
Output shape: (1, 24, 24, 4)
Kernel shape: (9, 9, 3, 4)
Bias shape:   (4,)
Mean absolute error = 1.0194157e-07
</pre></div>
</div>
<img alt="../../_images/05-tensorflow-cnn_18_1.svg" src="../../_images/05-tensorflow-cnn_18_1.svg" /></div>
</div>
<p>Constructing the corresponding <strong>Toeplitz matrix</strong> of the operation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@np</span><span class="o">.</span><span class="n">vectorize</span>
<span class="k">def</span> <span class="nf">np_relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1e-16</span><span class="p">)</span>

<span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">B</span><span class="p">,</span> <span class="n">H0</span><span class="p">,</span> <span class="n">W0</span><span class="p">,</span> <span class="n">c_in</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="n">H1</span><span class="p">,</span> <span class="n">W1</span> <span class="o">=</span> <span class="n">H0</span> <span class="o">-</span> <span class="n">h</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">W0</span> <span class="o">-</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">c_out</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Constructing the Toeplitz matrix</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">))</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_out</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_in</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">H1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">W1</span><span class="p">):</span>
                <span class="n">ii</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">W0</span> <span class="o">+</span> <span class="n">j</span>
                <span class="n">jj</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">W1</span> <span class="o">+</span> <span class="n">j</span>
                <span class="k">for</span> <span class="n">hh</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="p">):</span>
                    <span class="n">T</span><span class="p">[</span><span class="n">ii</span> <span class="o">+</span> <span class="p">(</span><span class="n">hh</span> <span class="o">*</span> <span class="n">W0</span><span class="p">):</span> <span class="n">ii</span> <span class="o">+</span> <span class="p">(</span><span class="n">hh</span> <span class="o">*</span> <span class="n">W0</span><span class="p">)</span> <span class="o">+</span> <span class="n">w</span><span class="p">,</span> <span class="n">jj</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="p">[</span><span class="n">hh</span><span class="p">,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Computing the output image</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_out</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">H1</span> <span class="o">*</span> <span class="n">W1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_in</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">k</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np_relu</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">H1</span><span class="p">,</span> <span class="n">W1</span><span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>    
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_20_0.svg" src="../../_images/05-tensorflow-cnn_20_0.svg" /></div>
</div>
<p>Looks good! Toeplitz matrices for the first input channel:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c_out</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">c</span><span class="p">,</span> <span class="n">k</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_22_0.svg" src="../../_images/05-tensorflow-cnn_22_0.svg" /></div>
</div>
<p>Sparsity of the leftmost matrix above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">T</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">(</span><span class="n">t</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">t</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0791015625
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="stride-and-padding">
<h3>Stride and padding<a class="headerlink" href="#stride-and-padding" title="Permalink to this headline">¶</a></h3>
<p>The above definition of convolution can be modified to include a parameter <span class="math notranslate nohighlight">\(s\)</span> called the <strong>stride</strong> that controls the step size of the kernel when it slides over the input image. A convolution layer with stride <span class="math notranslate nohighlight">\(s\)</span> computes:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
{\bar {\mathbf X}}_{ij,\, k} 
&amp;= \varphi\left({\boldsymbol u}_{k} + \sum_{c=0}^{{\mathsf c}_\text{in}-1}\sum_{x = 0}^{{\mathsf k}_h-1} \sum_{y=0}^{{\mathsf k}_w-1} {\mathbf X}_{si + x,\, sj + y,\, c} \, {\mathbf K}_{xyc,{k}} \right)
\end{aligned}
\]</div>
<p>for <span class="math notranslate nohighlight">\(k = 0, \ldots, {\mathsf c}_\text{out}-1.\)</span> This includes the original definition which has a step size of 1. Note that strided convolutions can be thought of as a form of downsampling (discussed below) since it results in a significant reduction in image size. A larger stride along with a large kernel size can be useful if objects are large relative to the dimension of the image. For example, AlexNet <span id="id1">[<a class="reference internal" href="../../intro.html#id21" title="Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097–1105. Curran Associates, Inc., 2012. URL: http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf.">KSH12</a>]</span> used a kernel of size 11×11 with a stride of 4 in the first layer since objects in the <a class="reference external" href="https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description">ImageNet dataset</a> tend to occupy more pixels.</p>
<br><div class="figure align-default" id="imagenet">
<a class="reference internal image-reference" href="../../_images/imagenet.jpeg"><img alt="../../_images/imagenet.jpeg" src="../../_images/imagenet.jpeg" style="width: 45em;" /></a>
<p class="caption"><span class="caption-number">Fig. 73 </span><span class="caption-text">Sample images from the ImageNet dataset. <span id="id2">[<a class="reference internal" href="../../intro.html#id20" title="Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: a large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, volume, 248-255. 2009. doi:10.1109/CVPR.2009.5206848.">DDS+09</a>]</span></span><a class="headerlink" href="#imagenet" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Padding.</strong> Observe that in the above definition of convolution, the kernel placed entirely within the input image. This has the disadvantage of being biased towards the center pixels, resulting in information loss on the edges of the input image.</p>
<p>Also notice that applying convolutions will always result in decreasing spatial dimension which limits the depth of the network. A simple fix is to simply pad the edges with zeros so the kernel can be placed over the edges:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>            
<span class="n">pad</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ZeroPadding2D</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pad</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(256, 34, 34, 1)
</pre></div>
</div>
<img alt="../../_images/05-tensorflow-cnn_28_1.svg" src="../../_images/05-tensorflow-cnn_28_1.svg" /></div>
</div>
</div>
<div class="section" id="output-size">
<h3>Output size<a class="headerlink" href="#output-size" title="Permalink to this headline">¶</a></h3>
<p>The spatial dimension of the output is directly influenced by padding <code class="docutils literal notranslate"><span class="pre">p</span></code> and stride <code class="docutils literal notranslate"><span class="pre">s</span></code>. Suppose the input feature map has width <code class="docutils literal notranslate"><span class="pre">W</span></code> and let the kernel have width <code class="docutils literal notranslate"><span class="pre">f</span></code>, then the output image has width <code class="docutils literal notranslate"><span class="pre">W_out</span> <span class="pre">=</span> <span class="pre">⌊(W</span> <span class="pre">+</span> <span class="pre">2p</span> <span class="pre">-</span> <span class="pre">f)/s⌋</span> <span class="pre">+</span> <span class="pre">1</span></code> assuming equal padding on both sides.</p>
<p>Directly using discrete convolution is not always desirable as some pixels of the input are essentially dropped because a kernel cannot be placed within the image to cover them following the set stride:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>input    <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span> <span class="m">5</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">9</span>
kernel   <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>       
               <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
         -----------------                     
output       <span class="m">3</span>     <span class="m">6</span>     
</pre></div>
</div>
<p>For odd kernel size <code class="docutils literal notranslate"><span class="pre">f</span></code> and unit stride <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">1</span></code>, we can use <code class="docutils literal notranslate"><span class="pre">2p</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">-</span> <span class="pre">1</span></code> to get same sized outputs and with the kernel covering the entire input in a symmetric manner. For this reason, and also for the sake of symmetry, we prefer <a class="reference external" href="https://datascience.stackexchange.com/a/23186">odd-sized kernels</a> for convolutions.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>input    <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span> <span class="m">5</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">9</span> <span class="m">0</span> <span class="m">0</span>
kernel   <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
           <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
                  ...
                       <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
                         <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
         -------------------------                        
output       <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span> <span class="m">5</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">9</span>
</pre></div>
</div>
<p>For strides <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>, the best practice is to choose a kernel size <code class="docutils literal notranslate"><span class="pre">f</span></code> and the smallest padding <code class="docutils literal notranslate"><span class="pre">p</span></code> such that <code class="docutils literal notranslate"><span class="pre">s</span></code> divides <code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">+</span> <span class="pre">2p</span> <span class="pre">-</span> <span class="pre">f</span></code> so the entire input image is covered symmetrically by the kernel in constructing the convolved image.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>input    <span class="m">0</span> <span class="m">1</span> <span class="m">2</span> <span class="m">3</span> <span class="m">4</span> <span class="m">5</span> <span class="m">6</span> <span class="m">7</span> <span class="m">8</span> <span class="m">9</span> <span class="m">0</span>
kernel   <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
               <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
                     <span class="m">0</span> <span class="m">0</span> <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
         ---------------------                         
output       <span class="m">2</span>     <span class="m">5</span>     <span class="m">8</span>
</pre></div>
</div>
<br><p><strong>Remark.</strong> The <code class="docutils literal notranslate"><span class="pre">padding</span></code> argument in convolutional layers in TensorFlow takes in either <code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code>. The <code class="docutils literal notranslate"><span class="pre">&quot;valid&quot;</span></code> setting means that no padding is used an the kernel is placed only where it can be validly placed within the image. As discussed above this can result in discarding some pixels in the right as well as bottom part of the image.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code> setting is a bit more tricky. Here the image is zero-padded as evenly as possible such that the output image has width <code class="docutils literal notranslate"><span class="pre">⌈W</span> <span class="pre">/</span> <span class="pre">s⌉</span></code>. So if <code class="docutils literal notranslate"><span class="pre">⌊(W</span> <span class="pre">+</span> <span class="pre">2p</span> <span class="pre">-</span> <span class="pre">f)</span> <span class="pre">/</span> <span class="pre">s⌋</span> <span class="pre">+</span> <span class="pre">1</span> <span class="pre">==</span> <span class="pre">⌈W</span> <span class="pre">/</span> <span class="pre">s⌉</span></code>, such as when <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">1</span></code> and <code class="docutils literal notranslate"><span class="pre">2p</span> <span class="pre">=</span> <span class="pre">f</span> <span class="pre">-</span> <span class="pre">1</span></code>, then we can use <code class="docutils literal notranslate"><span class="pre">&quot;same&quot;</span></code> to implement a symmetric construction of the output as described above. Otherwise, we can apply <code class="docutils literal notranslate"><span class="pre">ZeroPadding2D</span></code> prior to convolution, resize the input images, or adjust the filter size as needed.</p>
</div>
<div class="section" id="downsampling">
<h3>Downsampling<a class="headerlink" href="#downsampling" title="Permalink to this headline">¶</a></h3>
<p>For any unit of a hidden layer, its <strong>receptive field</strong> refers to all the units from all the previous layers that may affect the calculation of the unit during forward pass. In particular, units in the final classification layer should have a receptive field that contains the whole input image in the input layer. Otherwise, some parts of the input data will not improve the performance of the model for that class.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Figure 14.2</strong> in <span id="id3">[<a class="reference internal" href="../../intro.html#id7" title="Aurélien Géron. Hands-on machine learning with Scikit-Learn and TensorFlow : concepts, tools, and techniques to build intelligent systems, Second Edition. O'Reilly Media, Sebastopol, CA, 2019. ISBN 978-1491962299.">Geron19</a>]</span></p>
</div>
<div class="figure align-default" id="id15">
<a class="reference internal image-reference" href="../../_images/receptive_field.png"><img alt="../../_images/receptive_field.png" src="../../_images/receptive_field.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 74 </span><span class="caption-text">Receptive field of a pixel in the third layer.</span><a class="headerlink" href="#id15" title="Permalink to this image">¶</a></p>
</div>
<p>One way to increase receptive field is by <strong>downsampling</strong> which is defined as taking a sample, or aggregating samples, of pixels in the current layer so that we can pass a smaller input onto the next layer. This results in lower computational costs and a reduction in the capacity of the network which can be good. Downsampling is commonly done by means of a <strong>pooling</strong> operation.</p>
<p>A pooling layer operates like a convolutional layer in that we can set a stride, padding, and kernel size. But unlike the convolution operation, pooling is non-parameteric. <strong>Max-pooling</strong> takes
the maximum value in the region that is covered by its kernel. One effect of max pooling is that it provides invariance to small translations of the input at the cost of some information loss. Note that max-pooling works well with the ReLU activation since all activation values subject to comparison are all nonnegative.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span>
    <span class="p">[</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="p">[</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
    <span class="p">[</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
    <span class="p">[</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]</span>
<span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>

<span class="n">pool</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pool</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pool</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[5 9]
 [4 8]]
</pre></div>
</div>
<img alt="../../_images/05-tensorflow-cnn_37_1.svg" src="../../_images/05-tensorflow-cnn_37_1.svg" /></div>
</div>
<p>Note that pooling is applied to each channel separately, so that the number of output channels is maintained. This makes sense since we want only to compress the original input without affecting its semantic structure.
In practice, there are two commonly used settings: <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">2</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">2</span></code> where the pooling regions are do not overlap, and the more aggressive overlapping pooling with <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">3</span></code> and <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">=</span> <span class="pre">2</span></code>. Using larger kernel sizes can be too aggressive resulting in worse performance. Observe below that there is more loss in finer detail when using overlapping pooling (right).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cat</span> <span class="o">=</span> <span class="n">DATASET_DIR</span> <span class="o">/</span> <span class="s2">&quot;cat.jpg&quot;</span>
<span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">cat</span><span class="p">))</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">decode_image</span><span class="p">(</span><span class="n">image_raw</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">image</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;k = 2, s = 2&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)(</span><span class="n">image</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;k = 3, s = 2&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_39_0.svg" src="../../_images/05-tensorflow-cnn_39_0.svg" /></div>
</div>
</div>
</div>
<div class="section" id="implementing-a-convnet">
<h2>Implementing a convnet<a class="headerlink" href="#implementing-a-convnet" title="Permalink to this headline">¶</a></h2>
<p>In this section, we implement a <strong>convolutional neural network</strong> (CNN) for classifying <a class="reference external" href="https://keras.io/api/datasets/fashion_mnist/">FashionMNIST</a> <span id="id4">[<a class="reference internal" href="../../intro.html#id22" title="Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. CoRR, 2017. URL: http://arxiv.org/abs/1708.07747, arXiv:1708.07747.">XRV17</a>]</span> images using the Keras sequential API. This makes sense since a convnet is simply a stack of convolutional blocks, i.e. performing convolution, activation, and max-pooling, for feature extraction, followed by a dense classification subnetwork on the final extracted features. This section follows <span id="id5">[<a class="reference internal" href="../../intro.html#id24" title="Sebastian Raschka, Yuxi Liu, and Vahid Mirjalili. Machine Learning with PyTorch and Scikit-Learn. Packt Publishing, Birmingham, UK, 2022. ISBN 978-1801819312.">SRYLM22</a>]</span>.</p>
<p>For our implementation, we will use a width of 512 in the last dense layer instead of 1024 indicated in the figure below. This significantly reduces the number of parameters of the model. We also experiment with <a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization</a> <span id="id6">[<a class="reference internal" href="../../intro.html#id25" title="Sergey Ioffe and Christian Szegedy. Batch normalization: accelerating deep network training by reducing internal covariate shift. CoRR, 2015. URL: http://arxiv.org/abs/1502.03167, arXiv:1502.03167.">IS15</a>]</span> and see whether this improves model performance.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Figure source: <br>
<a class="reference external" href="https://github.com/rasbt/machine-learning-book/blob/main/ch14/figures/14_12.png"><code class="docutils literal notranslate"><span class="pre">github.com/rasbt/</span></code></a></p>
</div>
<div class="figure align-default" id="id16">
<img alt="../../_images/convnet.png" src="../../_images/convnet.png" />
<p class="caption"><span class="caption-number">Fig. 75 </span><span class="caption-text">Visualizing the structure of <code class="docutils literal notranslate"><span class="pre">model</span></code> below.</span><a class="headerlink" href="#id16" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="network-structure">
<h3>Network structure<a class="headerlink" href="#network-structure" title="Permalink to this headline">¶</a></h3>
<p>Observe that the network follows the pattern of stacking <code class="docutils literal notranslate"><span class="pre">[Conv</span> <span class="pre">→</span> <span class="pre">ReLU</span> <span class="pre">→</span> <span class="pre">Pool]</span></code> blocks. This is typical in network design: using blocks composed of layers that together forms a basic functional unit. Here the spatial dimensions are downsampled while increasing the number of output channels, then the resulting long vector is passed to a dense classification subnetwork.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_2 (Conv2D)           (None, 28, 28, 32)        832       
                                                                 
 batch_normalization (BatchN  (None, 28, 28, 32)       128       
 ormalization)                                                   
                                                                 
 re_lu (ReLU)                (None, 28, 28, 32)        0         
                                                                 
 max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         
 2D)                                                             
                                                                 
 conv2d_3 (Conv2D)           (None, 14, 14, 64)        51264     
                                                                 
 batch_normalization_1 (Batc  (None, 14, 14, 64)       256       
 hNormalization)                                                 
                                                                 
 re_lu_1 (ReLU)              (None, 14, 14, 64)        0         
                                                                 
 max_pooling2d_4 (MaxPooling  (None, 7, 7, 64)         0         
 2D)                                                             
                                                                 
 flatten (Flatten)           (None, 3136)              0         
                                                                 
 dense (Dense)               (None, 512)               1606144   
                                                                 
 dropout (Dropout)           (None, 512)               0         
                                                                 
 dense_1 (Dense)             (None, 10)                5130      
                                                                 
=================================================================
Total params: 1,663,754
Trainable params: 1,663,562
Non-trainable params: 192
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
    <span class="k">return</span> <span class="n">data</span> 

<span class="c1"># Load and preprocess MNIST data</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">fashion_mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Split train and validation sets</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>


<span class="c1"># Compile model with Adam and cross-entropy</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Train model on FashionMNIST data</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:40:21.891983: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-05-11 00:40:22.153262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>782/782 [==============================] - ETA: 0s - loss: 0.5333 - accuracy: 0.8147
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:40:35.232794: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>782/782 [==============================] - 15s 18ms/step - loss: 0.5333 - accuracy: 0.8147 - val_loss: 0.3316 - val_accuracy: 0.8760
Epoch 2/20
782/782 [==============================] - 14s 18ms/step - loss: 0.3492 - accuracy: 0.8727 - val_loss: 0.3008 - val_accuracy: 0.8896
Epoch 3/20
782/782 [==============================] - 14s 17ms/step - loss: 0.2996 - accuracy: 0.8913 - val_loss: 0.3114 - val_accuracy: 0.8878
Epoch 4/20
782/782 [==============================] - 13s 17ms/step - loss: 0.2673 - accuracy: 0.9025 - val_loss: 0.2472 - val_accuracy: 0.9073
Epoch 5/20
782/782 [==============================] - 13s 17ms/step - loss: 0.2454 - accuracy: 0.9104 - val_loss: 0.2239 - val_accuracy: 0.9156
Epoch 6/20
782/782 [==============================] - 14s 17ms/step - loss: 0.2241 - accuracy: 0.9175 - val_loss: 0.2262 - val_accuracy: 0.9148
Epoch 7/20
782/782 [==============================] - 13s 17ms/step - loss: 0.2061 - accuracy: 0.9235 - val_loss: 0.2273 - val_accuracy: 0.9184
Epoch 8/20
782/782 [==============================] - 13s 17ms/step - loss: 0.1916 - accuracy: 0.9287 - val_loss: 0.2343 - val_accuracy: 0.9151
Epoch 9/20
782/782 [==============================] - 14s 17ms/step - loss: 0.1762 - accuracy: 0.9348 - val_loss: 0.2331 - val_accuracy: 0.9176
Epoch 10/20
782/782 [==============================] - 13s 17ms/step - loss: 0.1613 - accuracy: 0.9400 - val_loss: 0.2147 - val_accuracy: 0.9195
Epoch 11/20
782/782 [==============================] - 14s 17ms/step - loss: 0.1477 - accuracy: 0.9459 - val_loss: 0.2364 - val_accuracy: 0.9129
Epoch 12/20
782/782 [==============================] - 14s 18ms/step - loss: 0.1371 - accuracy: 0.9490 - val_loss: 0.2193 - val_accuracy: 0.9220
Epoch 13/20
782/782 [==============================] - 14s 18ms/step - loss: 0.1254 - accuracy: 0.9539 - val_loss: 0.2308 - val_accuracy: 0.9196
Epoch 14/20
782/782 [==============================] - 14s 18ms/step - loss: 0.1133 - accuracy: 0.9564 - val_loss: 0.2280 - val_accuracy: 0.9238
Epoch 15/20
782/782 [==============================] - 14s 18ms/step - loss: 0.1056 - accuracy: 0.9602 - val_loss: 0.2507 - val_accuracy: 0.9164
Epoch 16/20
782/782 [==============================] - 14s 18ms/step - loss: 0.0969 - accuracy: 0.9641 - val_loss: 0.2340 - val_accuracy: 0.9286
Epoch 17/20
782/782 [==============================] - 14s 18ms/step - loss: 0.0899 - accuracy: 0.9652 - val_loss: 0.2465 - val_accuracy: 0.9206
Epoch 18/20
782/782 [==============================] - 14s 18ms/step - loss: 0.0828 - accuracy: 0.9688 - val_loss: 0.2494 - val_accuracy: 0.9242
Epoch 19/20
782/782 [==============================] - 14s 18ms/step - loss: 0.0789 - accuracy: 0.9701 - val_loss: 0.2528 - val_accuracy: 0.9247
Epoch 20/20
782/782 [==============================] - 14s 18ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.2644 - val_accuracy: 0.9243
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plotting result of Keras model training.&quot;&quot;&quot;</span>

    <span class="n">train_label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Train (</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">)&#39;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;Train&#39;</span>
    <span class="n">valid_label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;Valid (</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s1">)&#39;</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;Valid&#39;</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">train_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">valid_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C1&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="n">metric</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">train_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;val_</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">valid_label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C1&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_48_0.svg" src="../../_images/05-tensorflow-cnn_48_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>313/313 [==============================] - 2s 8ms/step - loss: 0.3148 - accuracy: 0.9184
Test accuracy: 0.9184000492095947
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;T-shirt/top&quot;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s2">&quot;Trouser&quot;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s2">&quot;Pullover&quot;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s2">&quot;Dress&quot;</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">:</span> <span class="s2">&quot;Coat&quot;</span><span class="p">,</span>
    <span class="mi">5</span><span class="p">:</span> <span class="s2">&quot;Sandal&quot;</span><span class="p">,</span>
    <span class="mi">6</span><span class="p">:</span> <span class="s2">&quot;Shirt&quot;</span><span class="p">,</span>
    <span class="mi">7</span><span class="p">:</span> <span class="s2">&quot;Sneaker&quot;</span><span class="p">,</span>
    <span class="mi">8</span><span class="p">:</span> <span class="s2">&quot;Bag&quot;</span><span class="p">,</span>
    <span class="mi">9</span><span class="p">:</span> <span class="s2">&quot;Ankle boot&quot;</span>
<span class="p">}</span>

<span class="n">pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_proba</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pred_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> 
    <span class="s1">&#39;proba&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">pred_proba</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pred</span><span class="p">)],</span> 
    <span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
<span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:45:01.581593: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
</div>
</div>
<p>Plotting the examples where model is least confident in its prediction:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">worst_preds</span> <span class="o">=</span> <span class="n">pred_table</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;proba&#39;</span><span class="p">)[:</span><span class="mi">12</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    <span class="n">img_index</span> <span class="o">=</span> <span class="n">worst_preds</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">img_index</span><span class="p">]</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">worst_preds</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="c1"># Plot</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([]);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;proba&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GT: </span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_52_0.svg" src="../../_images/05-tensorflow-cnn_52_0.svg" /></div>
</div>
</div>
<div class="section" id="effect-of-batch-normalization">
<h3>Effect of Batch Normalization<a class="headerlink" href="#effect-of-batch-normalization" title="Permalink to this headline">¶</a></h3>
<p>Since we already have our experiment set up, might as well run some tests. Recall that we fitted batch normalization layers after the convolutional layers. Let us see how this affects model training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_no_bn</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>


<span class="c1"># Build and compile with Adam and cross-entropy</span>
<span class="n">model_no_bn</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">model_no_bn</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span> 
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Train on FashionMNIST data</span>
<span class="n">hist_no_bn</span> <span class="o">=</span> <span class="n">model_no_bn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
  5/782 [..............................] - ETA: 11s - loss: 2.0375 - accuracy: 0.2875 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:45:04.545255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>782/782 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.8351
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:45:15.928418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>782/782 [==============================] - 13s 16ms/step - loss: 0.4585 - accuracy: 0.8351 - val_loss: 0.3117 - val_accuracy: 0.8859
Epoch 2/20
782/782 [==============================] - 13s 16ms/step - loss: 0.2973 - accuracy: 0.8907 - val_loss: 0.2701 - val_accuracy: 0.9002
Epoch 3/20
782/782 [==============================] - 13s 16ms/step - loss: 0.2511 - accuracy: 0.9077 - val_loss: 0.2771 - val_accuracy: 0.8978
Epoch 4/20
782/782 [==============================] - 12s 16ms/step - loss: 0.2224 - accuracy: 0.9181 - val_loss: 0.2214 - val_accuracy: 0.9188
Epoch 5/20
782/782 [==============================] - 12s 16ms/step - loss: 0.1972 - accuracy: 0.9282 - val_loss: 0.2225 - val_accuracy: 0.9149
Epoch 6/20
782/782 [==============================] - 13s 16ms/step - loss: 0.1785 - accuracy: 0.9340 - val_loss: 0.2182 - val_accuracy: 0.9202
Epoch 7/20
782/782 [==============================] - 13s 16ms/step - loss: 0.1601 - accuracy: 0.9400 - val_loss: 0.2052 - val_accuracy: 0.9275
Epoch 8/20
782/782 [==============================] - 12s 16ms/step - loss: 0.1413 - accuracy: 0.9474 - val_loss: 0.2226 - val_accuracy: 0.9240
Epoch 9/20
782/782 [==============================] - 13s 16ms/step - loss: 0.1256 - accuracy: 0.9533 - val_loss: 0.2245 - val_accuracy: 0.9220
Epoch 10/20
782/782 [==============================] - 13s 16ms/step - loss: 0.1150 - accuracy: 0.9564 - val_loss: 0.2316 - val_accuracy: 0.9230
Epoch 11/20
782/782 [==============================] - 13s 16ms/step - loss: 0.1041 - accuracy: 0.9608 - val_loss: 0.2423 - val_accuracy: 0.9227
Epoch 12/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0917 - accuracy: 0.9657 - val_loss: 0.2533 - val_accuracy: 0.9239
Epoch 13/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.2537 - val_accuracy: 0.9236
Epoch 14/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0738 - accuracy: 0.9723 - val_loss: 0.2628 - val_accuracy: 0.9240
Epoch 15/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0694 - accuracy: 0.9736 - val_loss: 0.2827 - val_accuracy: 0.9247
Epoch 16/20
782/782 [==============================] - 12s 16ms/step - loss: 0.0635 - accuracy: 0.9762 - val_loss: 0.3101 - val_accuracy: 0.9200
Epoch 17/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0556 - accuracy: 0.9793 - val_loss: 0.3089 - val_accuracy: 0.9214
Epoch 18/20
782/782 [==============================] - 12s 16ms/step - loss: 0.0545 - accuracy: 0.9794 - val_loss: 0.2932 - val_accuracy: 0.9253
Epoch 19/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.3378 - val_accuracy: 0.9232
Epoch 20/20
782/782 [==============================] - 13s 16ms/step - loss: 0.0474 - accuracy: 0.9822 - val_loss: 0.3244 - val_accuracy: 0.9241
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot on same axis as prev model</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist_no_bn</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;no BN&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_56_0.svg" src="../../_images/05-tensorflow-cnn_56_0.svg" /></div>
</div>
<p>Observe that the model with batch normalization exhibits less overfitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy (BN):     </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy (w/o BN): </span><span class="si">{</span><span class="n">model_no_bn</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy (BN):     91.84%
Test accuracy (w/o BN): 92.00%
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="data-augmentation">
<h2>Data augmentation<a class="headerlink" href="#data-augmentation" title="Permalink to this headline">¶</a></h2>
<p>In this section, we will create a convolutional network for classifying whether or not an image of a person is smiling or not. The dataset we will be using is <a class="reference external" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">CelebA</a> <span id="id7">[<a class="reference internal" href="../../intro.html#id23" title="Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV). December 2015.">LLWT15</a>]</span> which contains 202,599 images of celebrities’ faces. In addition, 40 binary facial attributes are available for each image. This section follows <span id="id8">[<a class="reference internal" href="../../intro.html#id24" title="Sebastian Raschka, Yuxi Liu, and Vahid Mirjalili. Machine Learning with PyTorch and Scikit-Learn. Packt Publishing, Birmingham, UK, 2022. ISBN 978-1801819312.">SRYLM22</a>]</span>.</p>
<p>To speed up training we will use only a small subset of 16,000 faces. However, this is a small dataset. To increase the size of the dataset, and improve generalization, we will use <strong>data augmentation</strong>. This technique incorporates transformed versions of the original images into the dataset resulting in a model that is robust to changes that should not affect semantics such as rotation and translation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">USER</span><span class="o">=</span><span class="s2">&quot;jessicali9530&quot;</span>
<span class="nv">DATASET</span><span class="o">=</span><span class="s2">&quot;celeba-dataset&quot;</span>
<span class="nv">DATA_DIR</span><span class="o">=</span>./data
mkdir <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>
kaggle datasets download -d <span class="si">${</span><span class="nv">USER</span><span class="si">}</span>/<span class="si">${</span><span class="nv">DATASET</span><span class="si">}</span> -p <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>
unzip <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">DATASET</span><span class="si">}</span>.zip -d <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">DATASET</span><span class="si">}</span> &gt; /dev/null
rm <span class="si">${</span><span class="nv">DATA_DIR</span><span class="si">}</span>/<span class="si">${</span><span class="nv">DATASET</span><span class="si">}</span>.zip
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mkdir: ./data: File exists
Downloading celeba-dataset.zip to ./data
 100%|████████████████████████████████▉| 1.33G/1.33G [09:24&lt;00:00, 3.13MB/s]
</pre></div>
</div>
<p>Plotting example images with their labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image_dir_path</span> <span class="o">=</span> <span class="n">DATASET_DIR</span> <span class="o">/</span> <span class="s2">&quot;celeba-dataset&quot;</span> <span class="o">/</span> <span class="s2">&quot;img_align_celeba&quot;</span> <span class="o">/</span> <span class="s2">&quot;img_align_celeba&quot;</span>
<span class="n">face_file_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">image_dir_path</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;*.jpg&quot;</span><span class="p">)])</span>

<span class="c1"># Get id -&gt; target dictionary</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="n">DATASET_DIR</span> <span class="o">/</span> <span class="s1">&#39;celeba-dataset&#39;</span>
<span class="n">attr</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">dataset_path</span> <span class="o">/</span> <span class="s1">&#39;list_attr_celeba.csv&#39;</span><span class="p">)[[</span><span class="s1">&#39;image_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Smiling&#39;</span><span class="p">]]</span>
<span class="n">attr</span><span class="p">[</span><span class="s1">&#39;Smiling&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">attr</span><span class="p">[</span><span class="s1">&#39;Smiling&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">get_smile</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">attr</span><span class="o">.</span><span class="n">image_id</span><span class="p">,</span> <span class="n">attr</span><span class="o">.</span><span class="n">Smiling</span><span class="p">))</span>

<span class="c1"># Plot examples from dataset</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    <span class="n">image_path</span> <span class="o">=</span> <span class="n">face_file_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">image_id</span> <span class="o">=</span> <span class="n">image_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">get_smile</span><span class="p">[</span><span class="n">image_id</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>

    <span class="c1"># Plot</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_id</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_64_0.svg" src="../../_images/05-tensorflow-cnn_64_0.svg" /></div>
</div>
<div class="section" id="transformations">
<h3>Transformations<a class="headerlink" href="#transformations" title="Permalink to this headline">¶</a></h3>
<p>For the sake of demonstration, we apply various transformations on a single image. These are cropping to a bounding box, flipping horizontally, adjusting the contrast, adjusting the brightness, and  center-cropping and resizing the resulting image back to its original size of 218×178. All of these are available in the <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/image"><code class="docutils literal notranslate"><span class="pre">tf.image</span></code></a> library.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get sample image</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[</span><span class="mi">11</span><span class="p">])</span>

<span class="c1"># Apply augmentations to sample image</span>
<span class="n">cropped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">crop_to_bounding_box</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
<span class="n">flipped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">contrast_adjusted</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">adjust_contrast</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mf">2.</span><span class="p">)</span>
<span class="n">brightness_adjusted</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">adjust_brightness</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">center_cropped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">central_crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">central_fraction</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">resized_center_cropped</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">center_cropped</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">218</span><span class="p">,</span> <span class="mi">178</span><span class="p">])</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="c1"># Visualize</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original image&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Crop&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Flip&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Contrast&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Brightness&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Center crop + Resize&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cropped</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">flipped</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">contrast_adjusted</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">brightness_adjusted</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">resized_center_cropped</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Transformations on a sample image&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_67_0.svg" src="../../_images/05-tensorflow-cnn_67_0.svg" /></div>
</div>
<p>Observe that the transformations above are all deterministic. The idea behind data augmentation is to inject randomness into these transformations to get new data points since these transformations do not change the label. For example, the parameters for contrast and brightness change can be drawn from some uniform distribution.</p>
<p>For our training dataset we apply a sequence of transformation: first we perform random cropping so the model can focus more on the face, this is followed by a random horizontal flip, and a final resize to 64×64. For test data, we remove the stochasticity as we want to avoid unnecessary information loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original image&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Random crop&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Random flip&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Resize&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[:</span><span class="mi">3</span><span class="p">]):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">178</span><span class="p">,</span> <span class="mi">178</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">random_flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span> <span class="o">/</span> <span class="mf">255.</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Sequence of random transforms on sample image&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_69_0.svg" src="../../_images/05-tensorflow-cnn_69_0.svg" /></div>
</div>
<p>The 64x64 images in the last column are those that will make up the training data. In the next section, we will define a tranformation pipeline and simulate how three sample images are presented to the model across multiple epochs.</p>
<p>Note that we prefer using exactly one transformed version of an image per epoch so that the model is not biased, in contrast to the alternative of using multiple transformations of a single image in one epoch. We also want to avoid cropping too aggressively, otherwise we might crop the mouth out of the image which is highly predictive of a smile.</p>
</div>
<div class="section" id="creating-the-augmented-dataset">
<h3>Creating the augmented dataset<a class="headerlink" href="#creating-the-augmented-dataset" title="Permalink to this headline">¶</a></h3>
<p>We now load the JPEG files into a TensorFlow dataset and apply the transformation to get a <code class="docutils literal notranslate"><span class="pre">MapDataset</span></code>. The whole process was introduced in a <a class="reference external" href="https://particle1331.github.io/inefficient-networks/notebooks/tensorflow/01-tensorflow-nn.html#dataset-from-local-files">previous notebook</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">augment</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Full image transformation pipeline.&quot;&quot;&quot;</span>
    
    <span class="k">if</span> <span class="n">augment</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">random_crop</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">178</span><span class="p">,</span> <span class="mi">178</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">random_flip_left_right</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">crop_to_bounding_box</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">offset_height</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">offset_width</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
            <span class="n">target_height</span><span class="o">=</span><span class="mi">178</span><span class="p">,</span> <span class="n">target_width</span><span class="o">=</span><span class="mi">178</span>
        <span class="p">)</span> <span class="c1"># (218 - 178)/2 = 20, (178 - 178)/2 = 0</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.</span>
    <span class="k">return</span> <span class="n">image</span>
    

<span class="k">def</span> <span class="nf">load_jpeg</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="n">image_raw</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">decode_jpeg</span><span class="p">(</span><span class="n">image_raw</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>


<span class="k">def</span> <span class="nf">image_id</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">file_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> 


<span class="k">def</span> <span class="nf">create_image_dataset</span><span class="p">(</span><span class="n">file_list</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_smile</span><span class="p">[</span><span class="n">image_id</span><span class="p">(</span><span class="n">file_path</span><span class="p">)]</span> <span class="k">for</span> <span class="n">file_path</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">]</span>
    <span class="n">paths_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">file_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
    <span class="n">image_ds</span> <span class="o">=</span> <span class="n">paths_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">label</span><span class="p">:</span> <span class="p">(</span><span class="n">load_jpeg</span><span class="p">(</span><span class="n">file_path</span><span class="p">),</span> <span class="n">label</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">image_ds</span>


<span class="c1"># Create train, valid, and test data loaders outside of train loop.</span>
<span class="c1"># Here we assume that the dataset is shuffled in disk. Not sure though.</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">create_image_dataset</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[:</span><span class="mi">16000</span><span class="p">])</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">train_ds</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>

<span class="n">valid_ds</span> <span class="o">=</span> <span class="n">create_image_dataset</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[</span><span class="mi">16000</span><span class="p">:</span><span class="mi">17000</span><span class="p">])</span>
<span class="n">valid_ds</span> <span class="o">=</span> <span class="n">valid_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>

<span class="n">test_ds</span> <span class="o">=</span> <span class="n">create_image_dataset</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[</span><span class="mi">17000</span><span class="p">:</span><span class="mi">18000</span><span class="p">])</span>
<span class="n">test_ds</span> <span class="o">=</span> <span class="n">test_ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Each dataset above is a <code class="docutils literal notranslate"><span class="pre">MapDataset</span></code> so that the mapping is applied lazily each time the dataset is iterated over. This is good since we want a different randomization for each epoch. Note that the ordering between <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> and <code class="docutils literal notranslate"><span class="pre">map</span></code> seems to be significant as well as setting <code class="docutils literal notranslate"><span class="pre">reshuffle_each_iteration</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>. This is done so that <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> <a class="reference external" href="https://github.com/tensorflow/tensorflow/issues/35682#issuecomment-578334425">maintains state across iterations</a> and we get different augmentations for each epoch. Batch size for the data loaders will have to be set up later.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># In this demo, we likewise create loaders outside of train loops</span>
<span class="n">train_demo</span> <span class="o">=</span> <span class="n">create_image_dataset</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">train_demo</span> <span class="o">=</span> <span class="n">train_demo</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>                           <span class="c1"># order important! </span>
<span class="n">train_demo</span> <span class="o">=</span> <span class="n">train_demo</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>     <span class="c1"># shuffle -&gt; map</span>
<span class="n">train_demo</span> <span class="o">=</span> <span class="n">train_demo</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Training</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_demo</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">epoch</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>

<span class="c1"># Inference: use same images for comparison</span>
<span class="n">test_demo</span> <span class="o">=</span> <span class="n">create_image_dataset</span><span class="p">(</span><span class="n">face_file_list</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
<span class="n">test_demo</span> <span class="o">=</span> <span class="n">test_demo</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">augment</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>
<span class="n">test_demo</span> <span class="o">=</span> <span class="n">test_demo</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_demo</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_75_0.svg" src="../../_images/05-tensorflow-cnn_75_0.svg" /></div>
</div>
<p>Checking if the labels are balanced so we can use accuracy as metric.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="p">[</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">valid_ds</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">]:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">16000</span><span class="p">)</span><span class="o">.</span><span class="n">as_numpy_iterator</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4813125
0.465
0.457
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="global-average-pooling">
<h3>Global average pooling<a class="headerlink" href="#global-average-pooling" title="Permalink to this headline">¶</a></h3>
<p>Now that we have our data loaders, let us look at the model architecture that we will use for smile classification. The input data goes through four convolutional layers to make 32, 64, 128, and 256 feature maps using 3×3 same convolutions, 2×2 nonoverlapping max-pooling blocks. Batch normalization layers are also included for regularization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(</span><span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(),</span>
    
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential_2&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d_6 (Conv2D)           (None, 64, 64, 32)        896       
                                                                 
 batch_normalization_2 (Batc  (None, 64, 64, 32)       128       
 hNormalization)                                                 
                                                                 
 re_lu_2 (ReLU)              (None, 64, 64, 32)        0         
                                                                 
 max_pooling2d_7 (MaxPooling  (None, 32, 32, 32)       0         
 2D)                                                             
                                                                 
 conv2d_7 (Conv2D)           (None, 32, 32, 64)        18496     
                                                                 
 batch_normalization_3 (Batc  (None, 32, 32, 64)       256       
 hNormalization)                                                 
                                                                 
 re_lu_3 (ReLU)              (None, 32, 32, 64)        0         
                                                                 
 max_pooling2d_8 (MaxPooling  (None, 16, 16, 64)       0         
 2D)                                                             
                                                                 
 conv2d_8 (Conv2D)           (None, 16, 16, 128)       73856     
                                                                 
 batch_normalization_4 (Batc  (None, 16, 16, 128)      512       
 hNormalization)                                                 
                                                                 
 re_lu_4 (ReLU)              (None, 16, 16, 128)       0         
                                                                 
 max_pooling2d_9 (MaxPooling  (None, 8, 8, 128)        0         
 2D)                                                             
                                                                 
 conv2d_9 (Conv2D)           (None, 8, 8, 256)         295168    
                                                                 
 batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      
 hNormalization)                                                 
                                                                 
 re_lu_5 (ReLU)              (None, 8, 8, 256)         0         
                                                                 
 global_average_pooling2d (G  (None, 256)              0         
 lobalAveragePooling2D)                                          
                                                                 
 flatten_2 (Flatten)         (None, 256)               0         
                                                                 
 dense_4 (Dense)             (None, 2)                 514       
                                                                 
=================================================================
Total params: 390,850
Trainable params: 389,890
Non-trainable params: 960
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>At the final convolutional layer, we have 256 many 8×8 feature maps. Flattening this into a 256×8×8 = 16,384 long vector results in the loss of learned semantic structure. Not to mention the excess in capacity of the dense layer that takes this vector as input.</p>
<p>An alternative that we use here is a <strong>global average-pooling</strong> (GAP) layer which averages all pixels in the 8×8 feature map into a single pixel. Averaging over the spatial dimensions can make the model more robust to small spatial translations in the input. But more importantly, compressing the spatial dimension allows us to preserve the channel structure, while reducing the output to a vector of length 256. This vector can then be passed to a dense layer to perform classification.</p>
<p>If the activations are nonnegative, each channel is forced to learn activation patterns, i.e. patterns in the kernel that result in activation, and averaging just summarizes how much the input matches this pattern. In fact, this has been used to construct maps which indicate the parts of the image that are discriminative!</p>
<br>
<div class="figure align-default" id="id17">
<a class="reference internal image-reference" href="../../_images/cams.png"><img alt="../../_images/cams.png" src="../../_images/cams.png" style="width: 50em;" /></a>
<p class="caption"><span class="caption-number">Fig. 76 </span><span class="caption-text">Global average pooling flattens the output of the convolutional base network. The outputs of the GAP layer are passed to a dense network with output dimension equal to the number of classes. It’s learned weight is interpreted as importance and is used to construct maps which highlight class-specific discriminative regions. <span id="id9">[<a class="reference internal" href="../../intro.html#id28" title="Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. 2015. URL: https://arxiv.org/abs/1512.04150, doi:10.48550/ARXIV.1512.04150.">ZKL+15</a>]</span></span><a class="headerlink" href="#id17" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="model-training-and-results">
<h3>Model training and results<a class="headerlink" href="#model-training-and-results" title="Permalink to this headline">¶</a></h3>
<p>Training the model with Adam with a learning rate of <span class="math notranslate nohighlight">\(10^{-3}\)</span> and a batch size of 32.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(),</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># Fit model with data augmentation</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/30
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:49:28.495254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>499/500 [============================&gt;.] - ETA: 0s - loss: 0.6101 - accuracy: 0.6649
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:49:44.401530: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>500/500 [==============================] - 17s 33ms/step - loss: 0.6097 - accuracy: 0.6652 - val_loss: 0.7737 - val_accuracy: 0.5380
Epoch 2/30
500/500 [==============================] - 19s 37ms/step - loss: 0.4768 - accuracy: 0.7765 - val_loss: 0.5752 - val_accuracy: 0.7400
Epoch 3/30
500/500 [==============================] - 19s 38ms/step - loss: 0.3859 - accuracy: 0.8295 - val_loss: 0.4073 - val_accuracy: 0.8190
Epoch 4/30
500/500 [==============================] - 19s 38ms/step - loss: 0.3434 - accuracy: 0.8508 - val_loss: 0.3869 - val_accuracy: 0.8290
Epoch 5/30
500/500 [==============================] - 19s 38ms/step - loss: 0.3204 - accuracy: 0.8599 - val_loss: 0.5897 - val_accuracy: 0.7640
Epoch 6/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2996 - accuracy: 0.8671 - val_loss: 1.0155 - val_accuracy: 0.6100
Epoch 7/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2884 - accuracy: 0.8751 - val_loss: 0.3268 - val_accuracy: 0.8600
Epoch 8/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2711 - accuracy: 0.8873 - val_loss: 0.2996 - val_accuracy: 0.8760
Epoch 9/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2649 - accuracy: 0.8859 - val_loss: 0.5211 - val_accuracy: 0.7930
Epoch 10/30
500/500 [==============================] - 19s 39ms/step - loss: 0.2577 - accuracy: 0.8893 - val_loss: 0.3531 - val_accuracy: 0.8520
Epoch 11/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2498 - accuracy: 0.8930 - val_loss: 0.5571 - val_accuracy: 0.7880
Epoch 12/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2420 - accuracy: 0.8988 - val_loss: 0.2915 - val_accuracy: 0.8800
Epoch 13/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2379 - accuracy: 0.8994 - val_loss: 0.2632 - val_accuracy: 0.8980
Epoch 14/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2348 - accuracy: 0.9016 - val_loss: 0.3222 - val_accuracy: 0.8590
Epoch 15/30
500/500 [==============================] - 19s 38ms/step - loss: 0.2277 - accuracy: 0.9070 - val_loss: 0.8159 - val_accuracy: 0.7400
Epoch 16/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2231 - accuracy: 0.9079 - val_loss: 1.0146 - val_accuracy: 0.6830
Epoch 17/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2236 - accuracy: 0.9068 - val_loss: 0.5508 - val_accuracy: 0.7620
Epoch 18/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2155 - accuracy: 0.9114 - val_loss: 0.2535 - val_accuracy: 0.8980
Epoch 19/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2207 - accuracy: 0.9068 - val_loss: 0.2755 - val_accuracy: 0.8880
Epoch 20/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2096 - accuracy: 0.9117 - val_loss: 0.2578 - val_accuracy: 0.8920
Epoch 21/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2101 - accuracy: 0.9147 - val_loss: 0.6154 - val_accuracy: 0.8000
Epoch 22/30
500/500 [==============================] - 20s 40ms/step - loss: 0.2087 - accuracy: 0.9124 - val_loss: 0.4346 - val_accuracy: 0.8310
Epoch 23/30
500/500 [==============================] - 20s 40ms/step - loss: 0.2068 - accuracy: 0.9146 - val_loss: 0.2470 - val_accuracy: 0.8980
Epoch 24/30
500/500 [==============================] - 20s 39ms/step - loss: 0.2079 - accuracy: 0.9146 - val_loss: 0.2386 - val_accuracy: 0.8990
Epoch 25/30
500/500 [==============================] - 21s 41ms/step - loss: 0.2016 - accuracy: 0.9170 - val_loss: 0.2435 - val_accuracy: 0.8940
Epoch 26/30
500/500 [==============================] - 21s 41ms/step - loss: 0.1951 - accuracy: 0.9159 - val_loss: 0.2351 - val_accuracy: 0.9030
Epoch 27/30
500/500 [==============================] - 21s 40ms/step - loss: 0.2016 - accuracy: 0.9151 - val_loss: 1.8816 - val_accuracy: 0.5220
Epoch 28/30
500/500 [==============================] - 21s 41ms/step - loss: 0.1980 - accuracy: 0.9169 - val_loss: 0.2377 - val_accuracy: 0.8970
Epoch 29/30
500/500 [==============================] - 21s 42ms/step - loss: 0.1943 - accuracy: 0.9202 - val_loss: 0.3136 - val_accuracy: 0.8720
Epoch 30/30
500/500 [==============================] - 21s 42ms/step - loss: 0.1916 - accuracy: 0.9203 - val_loss: 0.2933 - val_accuracy: 0.8800
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_85_0.svg" src="../../_images/05-tensorflow-cnn_85_0.svg" /></div>
</div>
<p>This looks good — the minimum validation loss roughly moves along with the train loss as the training progresses. One way to smooth out the validation curve is to get higher resolution input images. But here we already see that the network is able to learn with only 16,000 images by using data augmentation. In fact, if we turn off data augmentation, we get extreme divergence where the model overfits early on in the training. Again, this makes sense: adding random transformations on the train set makes it harder for the model to memorize it. At the same time, it learns to pick up representations that are invariant to these random perturbations in the inputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span> <span class="c1"># stochastic</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Valid accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy:  </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>  <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train accuracy: 90.96%
Valid accuracy: 88.00%
Test accuracy:  88.90%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_proba</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">)))</span>
<span class="n">pred_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">pred_proba</span><span class="p">,</span> <span class="s1">&#39;true&#39;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:59:36.198123: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">class_names</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;Not Smile&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Smile&#39;</span>
<span class="p">}</span>

<span class="c1"># Create distance of prediction from threshold of 0.5</span>
<span class="n">pred_table</span><span class="p">[</span><span class="s1">&#39;thresh_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">pred_table</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">pred_table</span><span class="p">[</span><span class="s1">&#39;correct&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_table</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">pred_table</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]</span>

<span class="n">confused</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_table</span>
    <span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;thresh_dist&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;correct == False&#39;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    <span class="n">img_index</span> <span class="o">=</span> <span class="n">confused</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">img_index</span><span class="p">]</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">confused</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="c1"># Plot</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([]);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pr(Smile)=</span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GT: </span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_89_0.svg" src="../../_images/05-tensorflow-cnn_89_0.svg" /></div>
</div>
<p><strong>Figure.</strong> Test examples where the model is confident (gives a predict probability near either 0 or 1) but also wrong. This gives us an opportunity to check whether some labels are flipped.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">near_threshold</span> <span class="o">=</span> <span class="n">pred_table</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;thresh_dist&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
    <span class="n">image_index</span> <span class="o">=</span> <span class="n">near_threshold</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">image_index</span><span class="p">]</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">near_threshold</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>

    <span class="c1"># Plot</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([]);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray_r&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pr(Smile)=</span><span class="si">{</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GT: </span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">row</span><span class="p">[</span><span class="s1">&#39;true&#39;</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_91_0.svg" src="../../_images/05-tensorflow-cnn_91_0.svg" /></div>
</div>
<p><strong>Figure.</strong> Test examples where model is not sure of whether the face is smiling or not (it gives a predict probability that is far from either 0 or 1). Probably the fact that teeth are either occluded or absent gives the model a hard time in detecting a smile.</p>
</div>
</div>
<div class="section" id="class-activation-maps">
<h2>Class activation maps<a class="headerlink" href="#class-activation-maps" title="Permalink to this headline">¶</a></h2>
<p>Previously, we introduced the concept of <strong>class activation maps</strong> (CAMs) in the context of GAP layers. We will try to construct this for the current model. This constuct a map which highlights the class-specific discriminative regions of an input image. The construction is based on the paper <span id="id10">[<a class="reference internal" href="../../intro.html#id28" title="Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep features for discriminative localization. 2015. URL: https://arxiv.org/abs/1512.04150, doi:10.48550/ARXIV.1512.04150.">ZKL+15</a>]</span>. So a GAP-CNN network does not only tell us what objects are present in the image, it also tells us where these objects are in the image and with no further training!</p>
<p>Looking at the model summary, note that the GAP layer output has 258 units. To construct the class activation maps, for each input <span class="math notranslate nohighlight">\(\mathbf x\)</span> we take the activations of the final ReLU layer which has shape (8, 8, 256) as <strong>activation maps</strong> <span class="math notranslate nohighlight">\(f_i(\mathbf x)\)</span> of shape (8, 8) for <span class="math notranslate nohighlight">\(i = 1, \ldots, 256\)</span> with nonnegative pixel values. Then, we take the weights <span class="math notranslate nohighlight">\(w_{ij}\)</span> of the dense layer which maps the output of the GAP layer to binary classes with label <span class="math notranslate nohighlight">\(j\)</span> (smile or not smile), and compute the sum</p>
<div class="math notranslate nohighlight">
\[\textsf{CAM}(\mathbf x, j) = \sum_{i=1}^{256}  f_i(\mathbf x) w_{ij}.\]</div>
<p>The resulting image is (8, 8) which we can resize for better resolution. Then we overlay this on the input image <span class="math notranslate nohighlight">\(\mathbf x\)</span> resized to the same height and width. Thus, what we’ve done here is expand the linear combination of zero-dimensional average activation values to a linear combination of 2-dimensional activation maps. CAMs are implemented in the following code block for test examples.</p>
<p>Note that class scores are obtained by a linear combination of the average pixel values in each activation map. Since spatial ordering is preserved by convolutional layers, then the activations should indicate which pixels in the input that is in its receptive field triggered the activation, i.e. whose local representation matched the pattern in the kernel. Moreover, since the activation maps have positive pixel values, we can use the weights in the linear combination as a measure of importance for each activation for a given class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>

<span class="k">def</span> <span class="nf">plot_cam</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">96</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot class activation maps (CAM) for each image in batch.</span>
<span class="sd">    The CAM will be taken with respect to the predicted label.&quot;&quot;&quot;</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">batch</span>
    <span class="n">class_label</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;Not Smile&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;Smile&#39;</span><span class="p">}</span>
    <span class="n">class_weight</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Resizing</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:][</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Apply layers up to final conv. activation. (1, 8, 8, 256) -&gt; (64, 256)</span>
        <span class="n">act_map</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">reduce</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">class_weight</span><span class="p">[:,</span> <span class="n">t</span><span class="p">][:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">cam</span> <span class="o">=</span> <span class="n">act_map</span> <span class="o">@</span> <span class="n">weights</span>
        <span class="n">cam</span> <span class="o">=</span> <span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">resize</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cam</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pr(Smile)=</span><span class="si">{</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GT: </span><span class="si">{</span><span class="n">class_label</span><span class="p">[</span><span class="n">y</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=-</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
        <span class="n">ax</span><span class="p">[</span><span class="nb">divmod</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>


<span class="n">plot_cam</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">12</span><span class="p">))))</span> <span class="c1"># Detect smile</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_95_0.svg" src="../../_images/05-tensorflow-cnn_95_0.svg" /></div>
</div>
<p><strong>Figure.</strong> CAMs of test images for the predicted class. Red regions indicate high activation values, hence local discriminative features. Notice that the model is able to find discriminative features around the mouth area for detecting the presence of smile. This becomes more defined as the confidence of the model increases. For not smile, although the activation regions are not as well-defined, the model still focuses around the mouth area.</p>
</div>
<div class="section" id="transfer-learning">
<h2>Transfer learning<a class="headerlink" href="#transfer-learning" title="Permalink to this headline">¶</a></h2>
<p><strong>Transfer learning</strong> consists of taking weights, and hence feature representations, learned on one problem, and leveraging them on a new, similar problem. In the following experiment, we will use a <a class="reference external" href="https://keras.io/api/applications/mobilenet/#mobilenetv2-function">MobileNetV2</a> <span id="id11">[<a class="reference internal" href="../../intro.html#id26" title="Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Inverted residuals and linear bottlenecks: mobile networks for classification, detection and segmentation. CoRR, 2018. URL: http://arxiv.org/abs/1801.04381, arXiv:1801.04381.">SHZ+18</a>]</span> model pretrained on ImageNet. This has around 2.3 million parameters and was designed to have fast inference times for resource constrained environments. This section follows the Keras guide <a class="reference external" href="https://keras.io/guides/transfer_learning/"><em>Transfer learning &amp; fine-tuning</em></a>.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><strong>Figure 8.12</strong> in <span id="id12">[<a class="reference internal" href="../../intro.html#id27" title="François Chollet. Deep Learning with Python, Second Edition. Abhishek Thakur, 2021. ISBN 9781617296864.">Cho21</a>]</span></p>
</div>
<div class="figure align-default" id="id18">
<a class="reference internal image-reference" href="../../_images/transfer-learning.png"><img alt="../../_images/transfer-learning.png" src="../../_images/transfer-learning.png" style="width: 40em;" /></a>
<p class="caption"><span class="caption-number">Fig. 77 </span><span class="caption-text">Replacing with a new classifiers while keeping the same convolutional base.</span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</div>
<p>Observe that the convolutional networks we encountered consist of two subnetworks: a convolutional base, that acts as a feature extractor, and a classifier on top of the base network, that processes the extracted features to get class probabilities. The idea behind transfer learning is that we can take the convolutional base, that is extensively trained on a large dataset, and use its learned representations to train a new classifier on a similar task. This leads us to the following workflow:</p>
<ol class="simple">
<li><p>Instantiate a base model and load pre-trained weights into it.</p></li>
<li><p>Freeze all layers in the base model by setting <code class="docutils literal notranslate"><span class="pre">trainable</span> <span class="pre">=</span> <span class="pre">False</span></code>.</p></li>
<li><p>Add new layers on top of the base model.</p></li>
<li><p>Train your new model on your new dataset.</p></li>
</ol>
<p>An alternative workflow is to pass the input data <em>once</em> to the base model to get feature vectors. These vectors are then used to train a new, smaller model. This is cheaper, but we obviously cannot use it along with data augmentation which transforms input data at each training iteration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">applications</span><span class="o">.</span><span class="n">MobileNetV2</span><span class="p">(</span>
    <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">,</span>         <span class="c1"># Load weights pre-trained on ImageNet.</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>    <span class="c1"># We will have to resize for our 64x64x3 train dataset.</span>
    <span class="n">include_top</span><span class="o">=</span><span class="kc">False</span>           <span class="c1"># Do not include the ImageNet classifier at the top.</span>
<span class="p">)</span>

<span class="c1"># Freeze the weights</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Stack a classification subnetwork on top</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Resizing</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">96</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>          <span class="c1"># Inference mode! ⚠⚠⚠</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">AvgPool2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>    <span class="c1"># 3x3x1280 -&gt; 1x1x1280. Remove for performance. </span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 64, 64, 3)]       0         
                                                                 
 resizing_1 (Resizing)       (None, 96, 96, 3)         0         
                                                                 
 mobilenetv2_1.00_96 (Functi  (None, 3, 3, 1280)       2257984   
 onal)                                                           
                                                                 
 average_pooling2d (AverageP  (None, 1, 1, 1280)       0         
 ooling2D)                                                       
                                                                 
 flatten_3 (Flatten)         (None, 1280)              0         
                                                                 
 dense_5 (Dense)             (None, 256)               327936    
                                                                 
 dropout_2 (Dropout)         (None, 256)               0         
                                                                 
 dense_6 (Dense)             (None, 1)                 257       
                                                                 
=================================================================
Total params: 2,586,177
Trainable params: 328,193
Non-trainable params: 2,257,984
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
<p>Setting <code class="docutils literal notranslate"><span class="pre">model.trainable</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code> recursively moves all trainable weights to non-trainable. In particular, this has the side-effect of disabling updates to batch normalization statistics. This makes sense since the trainable parameters that they interact with are frozen. Note that this side-effect is redundant with <code class="docutils literal notranslate"><span class="pre">base_model(x,</span> <span class="pre">training=False)</span></code>.</p>
<p><strong>Remark.</strong> This last setting will be important when we unfreeze the pretrained model weights for fine-tuning. According to the <a class="reference external" href="https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute">Keras FAQ</a>, it is usually still better to keep the moving statistics frozen when fine-tuning even while the trainable parameters are updating. Forcing pretrained model calls in inference mode does exactly this, as it is not overridden by training calls to <code class="docutils literal notranslate"><span class="pre">model</span></code> (see appendix).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">kr</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">()]</span>
<span class="p">)</span>

<span class="c1"># Fit model with data augmentation</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/20
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 00:59:42.058365: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>499/500 [============================&gt;.] - ETA: 0s - loss: 0.5902 - binary_accuracy: 0.6824
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 01:00:06.018983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>500/500 [==============================] - 29s 54ms/step - loss: 0.5905 - binary_accuracy: 0.6822 - val_loss: 0.5490 - val_binary_accuracy: 0.7350
Epoch 2/20
500/500 [==============================] - 31s 61ms/step - loss: 0.5291 - binary_accuracy: 0.7231 - val_loss: 0.5458 - val_binary_accuracy: 0.6940
Epoch 3/20
500/500 [==============================] - 31s 61ms/step - loss: 0.5165 - binary_accuracy: 0.7331 - val_loss: 0.5165 - val_binary_accuracy: 0.7360
Epoch 4/20
500/500 [==============================] - 30s 59ms/step - loss: 0.5071 - binary_accuracy: 0.7390 - val_loss: 0.5178 - val_binary_accuracy: 0.7380
Epoch 5/20
500/500 [==============================] - 31s 60ms/step - loss: 0.4993 - binary_accuracy: 0.7453 - val_loss: 0.5028 - val_binary_accuracy: 0.7410
Epoch 6/20
500/500 [==============================] - 32s 63ms/step - loss: 0.4909 - binary_accuracy: 0.7496 - val_loss: 0.5090 - val_binary_accuracy: 0.7430
Epoch 7/20
500/500 [==============================] - 30s 60ms/step - loss: 0.4873 - binary_accuracy: 0.7505 - val_loss: 0.5082 - val_binary_accuracy: 0.7420
Epoch 8/20
500/500 [==============================] - 31s 61ms/step - loss: 0.4884 - binary_accuracy: 0.7488 - val_loss: 0.5123 - val_binary_accuracy: 0.7310
Epoch 9/20
500/500 [==============================] - 31s 62ms/step - loss: 0.4808 - binary_accuracy: 0.7540 - val_loss: 0.5167 - val_binary_accuracy: 0.7420
Epoch 10/20
500/500 [==============================] - 29s 58ms/step - loss: 0.4775 - binary_accuracy: 0.7562 - val_loss: 0.5018 - val_binary_accuracy: 0.7420
Epoch 11/20
500/500 [==============================] - 27s 53ms/step - loss: 0.4775 - binary_accuracy: 0.7572 - val_loss: 0.5031 - val_binary_accuracy: 0.7440
Epoch 12/20
500/500 [==============================] - 26s 51ms/step - loss: 0.4693 - binary_accuracy: 0.7628 - val_loss: 0.5166 - val_binary_accuracy: 0.7460
Epoch 13/20
500/500 [==============================] - 26s 51ms/step - loss: 0.4659 - binary_accuracy: 0.7618 - val_loss: 0.5000 - val_binary_accuracy: 0.7540
Epoch 14/20
500/500 [==============================] - 25s 50ms/step - loss: 0.4549 - binary_accuracy: 0.7678 - val_loss: 0.5169 - val_binary_accuracy: 0.7450
Epoch 15/20
500/500 [==============================] - 27s 52ms/step - loss: 0.4616 - binary_accuracy: 0.7659 - val_loss: 0.5069 - val_binary_accuracy: 0.7350
Epoch 16/20
500/500 [==============================] - 25s 49ms/step - loss: 0.4510 - binary_accuracy: 0.7713 - val_loss: 0.5033 - val_binary_accuracy: 0.7460
Epoch 17/20
500/500 [==============================] - 27s 52ms/step - loss: 0.4573 - binary_accuracy: 0.7679 - val_loss: 0.4987 - val_binary_accuracy: 0.7500
Epoch 18/20
500/500 [==============================] - 26s 51ms/step - loss: 0.4511 - binary_accuracy: 0.7711 - val_loss: 0.5073 - val_binary_accuracy: 0.7560
Epoch 19/20
500/500 [==============================] - 26s 50ms/step - loss: 0.4446 - binary_accuracy: 0.7792 - val_loss: 0.5127 - val_binary_accuracy: 0.7430
Epoch 20/20
500/500 [==============================] - 26s 50ms/step - loss: 0.4460 - binary_accuracy: 0.7743 - val_loss: 0.5014 - val_binary_accuracy: 0.7330
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_102_0.svg" src="../../_images/05-tensorflow-cnn_102_0.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Valid accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy:  </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>  <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train accuracy: 76.91%
Valid accuracy: 73.30%
Test accuracy:  74.20%
</pre></div>
</div>
</div>
</div>
<div class="section" id="fine-tuning">
<h3>Fine-tuning<a class="headerlink" href="#fine-tuning" title="Permalink to this headline">¶</a></h3>
<p>A last, optional step, is <strong>fine-tuning</strong>, which consists of unfreezing the pre-trained model, or part of it, on the new task with very low learning rate. This can potentially achieve meaningful improvements. But could also potentially lead to quick overfitting due to the potentially large number of parameters in the base model which is why we use a small learning rate.</p>
<p>Note that it is critical to fine-tune a model only after the model with frozen layers has been trained to convergence. Mixing pretrained layers with randomly initialized layers will destroy the pretrained weights due to large gradient updates during the early stages of training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Unfreeze the base model.</span>
<span class="n">base_model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Recompile to take unfreezing into account.</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">1e-5</span><span class="p">),</span>  <span class="c1"># Very low learning rate</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">kr</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">kr</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">BinaryAccuracy</span><span class="p">()]</span>
<span class="p">)</span>

<span class="c1"># Train end-to-end. Be careful to stop before you overfit!</span>
<span class="n">callback</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span>
    <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Batch normalization still runs in inference mode. (See appendix.)</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">hist</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">32</span><span class="p">),</span> 
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> 
    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callback</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/10
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 01:10:58.178983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>500/500 [==============================] - ETA: 0s - loss: 0.4025 - binary_accuracy: 0.8043
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2022-05-11 01:12:02.662297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>500/500 [==============================] - 77s 139ms/step - loss: 0.4025 - binary_accuracy: 0.8043 - val_loss: 0.4203 - val_binary_accuracy: 0.8030
Epoch 2/10
500/500 [==============================] - 66s 131ms/step - loss: 0.3356 - binary_accuracy: 0.8391 - val_loss: 0.3758 - val_binary_accuracy: 0.7960
Epoch 3/10
500/500 [==============================] - 82s 161ms/step - loss: 0.2998 - binary_accuracy: 0.8614 - val_loss: 0.3294 - val_binary_accuracy: 0.8580
Epoch 4/10
500/500 [==============================] - 86s 167ms/step - loss: 0.2653 - binary_accuracy: 0.8793 - val_loss: 0.3113 - val_binary_accuracy: 0.8580
Epoch 5/10
500/500 [==============================] - 73s 143ms/step - loss: 0.2508 - binary_accuracy: 0.8854 - val_loss: 0.3151 - val_binary_accuracy: 0.8590
Epoch 6/10
500/500 [==============================] - 70s 138ms/step - loss: 0.2348 - binary_accuracy: 0.8911 - val_loss: 0.2852 - val_binary_accuracy: 0.8790
Epoch 7/10
500/500 [==============================] - 68s 134ms/step - loss: 0.2202 - binary_accuracy: 0.8988 - val_loss: 0.2970 - val_binary_accuracy: 0.8680
Epoch 8/10
500/500 [==============================] - 74s 147ms/step - loss: 0.2075 - binary_accuracy: 0.9045 - val_loss: 0.2784 - val_binary_accuracy: 0.8820
Epoch 9/10
500/500 [==============================] - 76s 151ms/step - loss: 0.1982 - binary_accuracy: 0.9109 - val_loss: 0.2803 - val_binary_accuracy: 0.8930
Epoch 10/10
500/500 [==============================] - 80s 159ms/step - loss: 0.1907 - binary_accuracy: 0.9121 - val_loss: 0.2866 - val_binary_accuracy: 0.8820
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_model_history</span><span class="p">(</span><span class="n">history</span><span class="o">=</span><span class="n">hist</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/05-tensorflow-cnn_107_0.svg" src="../../_images/05-tensorflow-cnn_107_0.svg" /></div>
</div>
<p>As expected, the model is starting to overfit due to overcapacity (the train-valid loss gap is widening). And we were not able to obtain a better test scores with fine-tuning (see below). It would be nice if we had better results with transfer learning (before fine-tuning), but this is likely due to hardware limitations. For more powerful systems, we expect better performing networks with transfer learning.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">train_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Valid accuracy: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">valid_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy:  </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_ds</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>  <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train accuracy: 91.79%
Valid accuracy: 88.20%
Test accuracy:  88.50%
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<div class="section" id="mobilenetv2-architecture">
<h3>MobileNetV2 architecture<a class="headerlink" href="#mobilenetv2-architecture" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;mobilenetv2_1.00_96&quot;
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 96, 96, 3)]  0           []                               
                                                                                                  
 Conv1 (Conv2D)                 (None, 48, 48, 32)   864         [&#39;input_1[0][0]&#39;]                
                                                                                                  
 bn_Conv1 (BatchNormalization)  (None, 48, 48, 32)   128         [&#39;Conv1[0][0]&#39;]                  
                                                                                                  
 Conv1_relu (ReLU)              (None, 48, 48, 32)   0           [&#39;bn_Conv1[0][0]&#39;]               
                                                                                                  
 expanded_conv_depthwise (Depth  (None, 48, 48, 32)  288         [&#39;Conv1_relu[0][0]&#39;]             
 wiseConv2D)                                                                                      
                                                                                                  
 expanded_conv_depthwise_BN (Ba  (None, 48, 48, 32)  128         [&#39;expanded_conv_depthwise[0][0]&#39;]
 tchNormalization)                                                                                
                                                                                                  
 expanded_conv_depthwise_relu (  (None, 48, 48, 32)  0           [&#39;expanded_conv_depthwise_BN[0][0
 ReLU)                                                           ]&#39;]                              
                                                                                                  
 expanded_conv_project (Conv2D)  (None, 48, 48, 16)  512         [&#39;expanded_conv_depthwise_relu[0]
                                                                 [0]&#39;]                            
                                                                                                  
 expanded_conv_project_BN (Batc  (None, 48, 48, 16)  64          [&#39;expanded_conv_project[0][0]&#39;]  
 hNormalization)                                                                                  
                                                                                                  
 block_1_expand (Conv2D)        (None, 48, 48, 96)   1536        [&#39;expanded_conv_project_BN[0][0]&#39;
                                                                 ]                                
                                                                                                  
 block_1_expand_BN (BatchNormal  (None, 48, 48, 96)  384         [&#39;block_1_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_1_expand_relu (ReLU)     (None, 48, 48, 96)   0           [&#39;block_1_expand_BN[0][0]&#39;]      
                                                                                                  
 block_1_pad (ZeroPadding2D)    (None, 49, 49, 96)   0           [&#39;block_1_expand_relu[0][0]&#39;]    
                                                                                                  
 block_1_depthwise (DepthwiseCo  (None, 24, 24, 96)  864         [&#39;block_1_pad[0][0]&#39;]            
 nv2D)                                                                                            
                                                                                                  
 block_1_depthwise_BN (BatchNor  (None, 24, 24, 96)  384         [&#39;block_1_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_1_depthwise_relu (ReLU)  (None, 24, 24, 96)   0           [&#39;block_1_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_1_project (Conv2D)       (None, 24, 24, 24)   2304        [&#39;block_1_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_1_project_BN (BatchNorma  (None, 24, 24, 24)  96          [&#39;block_1_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_2_expand (Conv2D)        (None, 24, 24, 144)  3456        [&#39;block_1_project_BN[0][0]&#39;]     
                                                                                                  
 block_2_expand_BN (BatchNormal  (None, 24, 24, 144)  576        [&#39;block_2_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_2_expand_relu (ReLU)     (None, 24, 24, 144)  0           [&#39;block_2_expand_BN[0][0]&#39;]      
                                                                                                  
 block_2_depthwise (DepthwiseCo  (None, 24, 24, 144)  1296       [&#39;block_2_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_2_depthwise_BN (BatchNor  (None, 24, 24, 144)  576        [&#39;block_2_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_2_depthwise_relu (ReLU)  (None, 24, 24, 144)  0           [&#39;block_2_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_2_project (Conv2D)       (None, 24, 24, 24)   3456        [&#39;block_2_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_2_project_BN (BatchNorma  (None, 24, 24, 24)  96          [&#39;block_2_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_2_add (Add)              (None, 24, 24, 24)   0           [&#39;block_1_project_BN[0][0]&#39;,     
                                                                  &#39;block_2_project_BN[0][0]&#39;]     
                                                                                                  
 block_3_expand (Conv2D)        (None, 24, 24, 144)  3456        [&#39;block_2_add[0][0]&#39;]            
                                                                                                  
 block_3_expand_BN (BatchNormal  (None, 24, 24, 144)  576        [&#39;block_3_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_3_expand_relu (ReLU)     (None, 24, 24, 144)  0           [&#39;block_3_expand_BN[0][0]&#39;]      
                                                                                                  
 block_3_pad (ZeroPadding2D)    (None, 25, 25, 144)  0           [&#39;block_3_expand_relu[0][0]&#39;]    
                                                                                                  
 block_3_depthwise (DepthwiseCo  (None, 12, 12, 144)  1296       [&#39;block_3_pad[0][0]&#39;]            
 nv2D)                                                                                            
                                                                                                  
 block_3_depthwise_BN (BatchNor  (None, 12, 12, 144)  576        [&#39;block_3_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_3_depthwise_relu (ReLU)  (None, 12, 12, 144)  0           [&#39;block_3_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_3_project (Conv2D)       (None, 12, 12, 32)   4608        [&#39;block_3_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_3_project_BN (BatchNorma  (None, 12, 12, 32)  128         [&#39;block_3_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_4_expand (Conv2D)        (None, 12, 12, 192)  6144        [&#39;block_3_project_BN[0][0]&#39;]     
                                                                                                  
 block_4_expand_BN (BatchNormal  (None, 12, 12, 192)  768        [&#39;block_4_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_4_expand_relu (ReLU)     (None, 12, 12, 192)  0           [&#39;block_4_expand_BN[0][0]&#39;]      
                                                                                                  
 block_4_depthwise (DepthwiseCo  (None, 12, 12, 192)  1728       [&#39;block_4_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_4_depthwise_BN (BatchNor  (None, 12, 12, 192)  768        [&#39;block_4_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_4_depthwise_relu (ReLU)  (None, 12, 12, 192)  0           [&#39;block_4_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_4_project (Conv2D)       (None, 12, 12, 32)   6144        [&#39;block_4_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_4_project_BN (BatchNorma  (None, 12, 12, 32)  128         [&#39;block_4_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_4_add (Add)              (None, 12, 12, 32)   0           [&#39;block_3_project_BN[0][0]&#39;,     
                                                                  &#39;block_4_project_BN[0][0]&#39;]     
                                                                                                  
 block_5_expand (Conv2D)        (None, 12, 12, 192)  6144        [&#39;block_4_add[0][0]&#39;]            
                                                                                                  
 block_5_expand_BN (BatchNormal  (None, 12, 12, 192)  768        [&#39;block_5_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_5_expand_relu (ReLU)     (None, 12, 12, 192)  0           [&#39;block_5_expand_BN[0][0]&#39;]      
                                                                                                  
 block_5_depthwise (DepthwiseCo  (None, 12, 12, 192)  1728       [&#39;block_5_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_5_depthwise_BN (BatchNor  (None, 12, 12, 192)  768        [&#39;block_5_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_5_depthwise_relu (ReLU)  (None, 12, 12, 192)  0           [&#39;block_5_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_5_project (Conv2D)       (None, 12, 12, 32)   6144        [&#39;block_5_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_5_project_BN (BatchNorma  (None, 12, 12, 32)  128         [&#39;block_5_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_5_add (Add)              (None, 12, 12, 32)   0           [&#39;block_4_add[0][0]&#39;,            
                                                                  &#39;block_5_project_BN[0][0]&#39;]     
                                                                                                  
 block_6_expand (Conv2D)        (None, 12, 12, 192)  6144        [&#39;block_5_add[0][0]&#39;]            
                                                                                                  
 block_6_expand_BN (BatchNormal  (None, 12, 12, 192)  768        [&#39;block_6_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_6_expand_relu (ReLU)     (None, 12, 12, 192)  0           [&#39;block_6_expand_BN[0][0]&#39;]      
                                                                                                  
 block_6_pad (ZeroPadding2D)    (None, 13, 13, 192)  0           [&#39;block_6_expand_relu[0][0]&#39;]    
                                                                                                  
 block_6_depthwise (DepthwiseCo  (None, 6, 6, 192)   1728        [&#39;block_6_pad[0][0]&#39;]            
 nv2D)                                                                                            
                                                                                                  
 block_6_depthwise_BN (BatchNor  (None, 6, 6, 192)   768         [&#39;block_6_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_6_depthwise_relu (ReLU)  (None, 6, 6, 192)    0           [&#39;block_6_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_6_project (Conv2D)       (None, 6, 6, 64)     12288       [&#39;block_6_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_6_project_BN (BatchNorma  (None, 6, 6, 64)    256         [&#39;block_6_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_7_expand (Conv2D)        (None, 6, 6, 384)    24576       [&#39;block_6_project_BN[0][0]&#39;]     
                                                                                                  
 block_7_expand_BN (BatchNormal  (None, 6, 6, 384)   1536        [&#39;block_7_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_7_expand_relu (ReLU)     (None, 6, 6, 384)    0           [&#39;block_7_expand_BN[0][0]&#39;]      
                                                                                                  
 block_7_depthwise (DepthwiseCo  (None, 6, 6, 384)   3456        [&#39;block_7_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_7_depthwise_BN (BatchNor  (None, 6, 6, 384)   1536        [&#39;block_7_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_7_depthwise_relu (ReLU)  (None, 6, 6, 384)    0           [&#39;block_7_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_7_project (Conv2D)       (None, 6, 6, 64)     24576       [&#39;block_7_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_7_project_BN (BatchNorma  (None, 6, 6, 64)    256         [&#39;block_7_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_7_add (Add)              (None, 6, 6, 64)     0           [&#39;block_6_project_BN[0][0]&#39;,     
                                                                  &#39;block_7_project_BN[0][0]&#39;]     
                                                                                                  
 block_8_expand (Conv2D)        (None, 6, 6, 384)    24576       [&#39;block_7_add[0][0]&#39;]            
                                                                                                  
 block_8_expand_BN (BatchNormal  (None, 6, 6, 384)   1536        [&#39;block_8_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_8_expand_relu (ReLU)     (None, 6, 6, 384)    0           [&#39;block_8_expand_BN[0][0]&#39;]      
                                                                                                  
 block_8_depthwise (DepthwiseCo  (None, 6, 6, 384)   3456        [&#39;block_8_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_8_depthwise_BN (BatchNor  (None, 6, 6, 384)   1536        [&#39;block_8_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_8_depthwise_relu (ReLU)  (None, 6, 6, 384)    0           [&#39;block_8_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_8_project (Conv2D)       (None, 6, 6, 64)     24576       [&#39;block_8_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_8_project_BN (BatchNorma  (None, 6, 6, 64)    256         [&#39;block_8_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_8_add (Add)              (None, 6, 6, 64)     0           [&#39;block_7_add[0][0]&#39;,            
                                                                  &#39;block_8_project_BN[0][0]&#39;]     
                                                                                                  
 block_9_expand (Conv2D)        (None, 6, 6, 384)    24576       [&#39;block_8_add[0][0]&#39;]            
                                                                                                  
 block_9_expand_BN (BatchNormal  (None, 6, 6, 384)   1536        [&#39;block_9_expand[0][0]&#39;]         
 ization)                                                                                         
                                                                                                  
 block_9_expand_relu (ReLU)     (None, 6, 6, 384)    0           [&#39;block_9_expand_BN[0][0]&#39;]      
                                                                                                  
 block_9_depthwise (DepthwiseCo  (None, 6, 6, 384)   3456        [&#39;block_9_expand_relu[0][0]&#39;]    
 nv2D)                                                                                            
                                                                                                  
 block_9_depthwise_BN (BatchNor  (None, 6, 6, 384)   1536        [&#39;block_9_depthwise[0][0]&#39;]      
 malization)                                                                                      
                                                                                                  
 block_9_depthwise_relu (ReLU)  (None, 6, 6, 384)    0           [&#39;block_9_depthwise_BN[0][0]&#39;]   
                                                                                                  
 block_9_project (Conv2D)       (None, 6, 6, 64)     24576       [&#39;block_9_depthwise_relu[0][0]&#39;] 
                                                                                                  
 block_9_project_BN (BatchNorma  (None, 6, 6, 64)    256         [&#39;block_9_project[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_9_add (Add)              (None, 6, 6, 64)     0           [&#39;block_8_add[0][0]&#39;,            
                                                                  &#39;block_9_project_BN[0][0]&#39;]     
                                                                                                  
 block_10_expand (Conv2D)       (None, 6, 6, 384)    24576       [&#39;block_9_add[0][0]&#39;]            
                                                                                                  
 block_10_expand_BN (BatchNorma  (None, 6, 6, 384)   1536        [&#39;block_10_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_10_expand_relu (ReLU)    (None, 6, 6, 384)    0           [&#39;block_10_expand_BN[0][0]&#39;]     
                                                                                                  
 block_10_depthwise (DepthwiseC  (None, 6, 6, 384)   3456        [&#39;block_10_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_10_depthwise_BN (BatchNo  (None, 6, 6, 384)   1536        [&#39;block_10_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_10_depthwise_relu (ReLU)  (None, 6, 6, 384)   0           [&#39;block_10_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_10_project (Conv2D)      (None, 6, 6, 96)     36864       [&#39;block_10_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_10_project_BN (BatchNorm  (None, 6, 6, 96)    384         [&#39;block_10_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_11_expand (Conv2D)       (None, 6, 6, 576)    55296       [&#39;block_10_project_BN[0][0]&#39;]    
                                                                                                  
 block_11_expand_BN (BatchNorma  (None, 6, 6, 576)   2304        [&#39;block_11_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_11_expand_relu (ReLU)    (None, 6, 6, 576)    0           [&#39;block_11_expand_BN[0][0]&#39;]     
                                                                                                  
 block_11_depthwise (DepthwiseC  (None, 6, 6, 576)   5184        [&#39;block_11_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_11_depthwise_BN (BatchNo  (None, 6, 6, 576)   2304        [&#39;block_11_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_11_depthwise_relu (ReLU)  (None, 6, 6, 576)   0           [&#39;block_11_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_11_project (Conv2D)      (None, 6, 6, 96)     55296       [&#39;block_11_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_11_project_BN (BatchNorm  (None, 6, 6, 96)    384         [&#39;block_11_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_11_add (Add)             (None, 6, 6, 96)     0           [&#39;block_10_project_BN[0][0]&#39;,    
                                                                  &#39;block_11_project_BN[0][0]&#39;]    
                                                                                                  
 block_12_expand (Conv2D)       (None, 6, 6, 576)    55296       [&#39;block_11_add[0][0]&#39;]           
                                                                                                  
 block_12_expand_BN (BatchNorma  (None, 6, 6, 576)   2304        [&#39;block_12_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_12_expand_relu (ReLU)    (None, 6, 6, 576)    0           [&#39;block_12_expand_BN[0][0]&#39;]     
                                                                                                  
 block_12_depthwise (DepthwiseC  (None, 6, 6, 576)   5184        [&#39;block_12_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_12_depthwise_BN (BatchNo  (None, 6, 6, 576)   2304        [&#39;block_12_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_12_depthwise_relu (ReLU)  (None, 6, 6, 576)   0           [&#39;block_12_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_12_project (Conv2D)      (None, 6, 6, 96)     55296       [&#39;block_12_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_12_project_BN (BatchNorm  (None, 6, 6, 96)    384         [&#39;block_12_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_12_add (Add)             (None, 6, 6, 96)     0           [&#39;block_11_add[0][0]&#39;,           
                                                                  &#39;block_12_project_BN[0][0]&#39;]    
                                                                                                  
 block_13_expand (Conv2D)       (None, 6, 6, 576)    55296       [&#39;block_12_add[0][0]&#39;]           
                                                                                                  
 block_13_expand_BN (BatchNorma  (None, 6, 6, 576)   2304        [&#39;block_13_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_13_expand_relu (ReLU)    (None, 6, 6, 576)    0           [&#39;block_13_expand_BN[0][0]&#39;]     
                                                                                                  
 block_13_pad (ZeroPadding2D)   (None, 7, 7, 576)    0           [&#39;block_13_expand_relu[0][0]&#39;]   
                                                                                                  
 block_13_depthwise (DepthwiseC  (None, 3, 3, 576)   5184        [&#39;block_13_pad[0][0]&#39;]           
 onv2D)                                                                                           
                                                                                                  
 block_13_depthwise_BN (BatchNo  (None, 3, 3, 576)   2304        [&#39;block_13_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_13_depthwise_relu (ReLU)  (None, 3, 3, 576)   0           [&#39;block_13_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_13_project (Conv2D)      (None, 3, 3, 160)    92160       [&#39;block_13_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_13_project_BN (BatchNorm  (None, 3, 3, 160)   640         [&#39;block_13_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_14_expand (Conv2D)       (None, 3, 3, 960)    153600      [&#39;block_13_project_BN[0][0]&#39;]    
                                                                                                  
 block_14_expand_BN (BatchNorma  (None, 3, 3, 960)   3840        [&#39;block_14_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_14_expand_relu (ReLU)    (None, 3, 3, 960)    0           [&#39;block_14_expand_BN[0][0]&#39;]     
                                                                                                  
 block_14_depthwise (DepthwiseC  (None, 3, 3, 960)   8640        [&#39;block_14_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_14_depthwise_BN (BatchNo  (None, 3, 3, 960)   3840        [&#39;block_14_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_14_depthwise_relu (ReLU)  (None, 3, 3, 960)   0           [&#39;block_14_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_14_project (Conv2D)      (None, 3, 3, 160)    153600      [&#39;block_14_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_14_project_BN (BatchNorm  (None, 3, 3, 160)   640         [&#39;block_14_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_14_add (Add)             (None, 3, 3, 160)    0           [&#39;block_13_project_BN[0][0]&#39;,    
                                                                  &#39;block_14_project_BN[0][0]&#39;]    
                                                                                                  
 block_15_expand (Conv2D)       (None, 3, 3, 960)    153600      [&#39;block_14_add[0][0]&#39;]           
                                                                                                  
 block_15_expand_BN (BatchNorma  (None, 3, 3, 960)   3840        [&#39;block_15_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_15_expand_relu (ReLU)    (None, 3, 3, 960)    0           [&#39;block_15_expand_BN[0][0]&#39;]     
                                                                                                  
 block_15_depthwise (DepthwiseC  (None, 3, 3, 960)   8640        [&#39;block_15_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_15_depthwise_BN (BatchNo  (None, 3, 3, 960)   3840        [&#39;block_15_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_15_depthwise_relu (ReLU)  (None, 3, 3, 960)   0           [&#39;block_15_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_15_project (Conv2D)      (None, 3, 3, 160)    153600      [&#39;block_15_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_15_project_BN (BatchNorm  (None, 3, 3, 160)   640         [&#39;block_15_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 block_15_add (Add)             (None, 3, 3, 160)    0           [&#39;block_14_add[0][0]&#39;,           
                                                                  &#39;block_15_project_BN[0][0]&#39;]    
                                                                                                  
 block_16_expand (Conv2D)       (None, 3, 3, 960)    153600      [&#39;block_15_add[0][0]&#39;]           
                                                                                                  
 block_16_expand_BN (BatchNorma  (None, 3, 3, 960)   3840        [&#39;block_16_expand[0][0]&#39;]        
 lization)                                                                                        
                                                                                                  
 block_16_expand_relu (ReLU)    (None, 3, 3, 960)    0           [&#39;block_16_expand_BN[0][0]&#39;]     
                                                                                                  
 block_16_depthwise (DepthwiseC  (None, 3, 3, 960)   8640        [&#39;block_16_expand_relu[0][0]&#39;]   
 onv2D)                                                                                           
                                                                                                  
 block_16_depthwise_BN (BatchNo  (None, 3, 3, 960)   3840        [&#39;block_16_depthwise[0][0]&#39;]     
 rmalization)                                                                                     
                                                                                                  
 block_16_depthwise_relu (ReLU)  (None, 3, 3, 960)   0           [&#39;block_16_depthwise_BN[0][0]&#39;]  
                                                                                                  
 block_16_project (Conv2D)      (None, 3, 3, 320)    307200      [&#39;block_16_depthwise_relu[0][0]&#39;]
                                                                                                  
 block_16_project_BN (BatchNorm  (None, 3, 3, 320)   1280        [&#39;block_16_project[0][0]&#39;]       
 alization)                                                                                       
                                                                                                  
 Conv_1 (Conv2D)                (None, 3, 3, 1280)   409600      [&#39;block_16_project_BN[0][0]&#39;]    
                                                                                                  
 Conv_1_bn (BatchNormalization)  (None, 3, 3, 1280)  5120        [&#39;Conv_1[0][0]&#39;]                 
                                                                                                  
 out_relu (ReLU)                (None, 3, 3, 1280)   0           [&#39;Conv_1_bn[0][0]&#39;]              
                                                                                                  
==================================================================================================
Total params: 2,257,984
Trainable params: 2,223,872
Non-trainable params: 34,112
__________________________________________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="batch-normalization-layers-in-transfer-learning">
<h3>Batch normalization layers in transfer learning<a class="headerlink" href="#batch-normalization-layers-in-transfer-learning" title="Permalink to this headline">¶</a></h3>
<p>Testing two facts about batch norm layers: 1) that batch norm layers are forced to run in inference mode when weights are frozen — these are, in principle, unrelated concepts — and 2) setting <code class="docutils literal notranslate"><span class="pre">base_model</span></code> calls to inference mode keeps its batch normalization layers in inference mode even if outer <code class="docutils literal notranslate"><span class="pre">model</span></code> calls are in training mode.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">training_mean_change</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bn_layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Max change in mean of BN layer after one call in training mode.&quot;&quot;&quot;</span>

    <span class="c1"># Get sample input</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="c1"># Change in mean after one call in train mode</span>
    <span class="n">u0</span> <span class="o">=</span> <span class="n">bn_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">u1</span> <span class="o">=</span> <span class="n">bn_layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">u1</span> <span class="o">-</span> <span class="n">u0</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>


<span class="c1"># Control: training mode, trainable weights</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">h</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">training_mean_change</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bn_layer</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>batch_normalization
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.00051729346
</pre></div>
</div>
</div>
</div>
<p>Running the same experiment with frozen weights in training mode. Getting <code class="docutils literal notranslate"><span class="pre">0.0</span></code> proves the first fact above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Freeze weights =&gt; BN inference mode</span>
<span class="n">model</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">training_mean_change</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bn_layer</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
</div>
</div>
<p>Next, we mimic the network structure for a transfer learning fine-tuning task. Recall that <code class="docutils literal notranslate"><span class="pre">base_model</span></code> is set in inference mode inside <code class="docutils literal notranslate"><span class="pre">model</span></code>. Getting <code class="docutils literal notranslate"><span class="pre">0.0</span></code> with trainable weights and running the outer model in training mode proves the second fact above about BN implementation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># &quot;Pretrained model&quot;</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">)(</span><span class="n">h</span><span class="p">)</span>
<span class="n">base_model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Pretrained model in inference mode</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">y</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Model training...</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="n">training_mean_change</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">bn_layer</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>batch_normalization_1
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks/tensorflow"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="04-tensorflow-optim-init.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Initialization and Optimization</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="06-tensorflow-rnns.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Recurrent Neural Networks</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By 𝗥𝗼𝗻 𝗠𝗲𝗱𝗶𝗻𝗮. Powered by <a href="https://jupyterbook.org">Jupyter Book</a>.<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>