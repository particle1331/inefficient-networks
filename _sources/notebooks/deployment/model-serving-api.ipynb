{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Serving API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=brightgreen)\n",
    "[![Source](https://img.shields.io/static/v1.svg?label=GitHub&message=Source&color=181717&logo=GitHub)](https://github.com/particle1331/inefficient-networks/blob/master/docs/notebooks/deployment/model-serving-api.ipynb)\n",
    "[![Stars](https://img.shields.io/github/stars/particle1331/inefficient-networks?style=social)](https://github.com/particle1331/inefficient-networks)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes we will be interested two aspects of the [REST architecture](https://restfulapi.net/): 1) having a uniform interface for transferring [resources](https://restfulapi.net/resource-naming/) between client and server, and 2) that each request from the client to the server must be [stateless](https://ruben.verborgh.org/blog/2012/08/24/rest-wheres-my-state/). \n",
    "In particular, looking at a request provides us all the context used by the server to process the interaction. Note that this does not necessarily mean that the result of this interaction is deterministic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will develop an API that exposes a single POST endpoint that serves prediction from the regression model described in the previous article. This can be consumed by an application as a dependency or as a [separate microservice](https://aws.amazon.com/microservices/). Note that while we will keep REST principles in mind, we only loosely adhere to them. In particular, we will be using [FastAPI](https://fastapi.tiangolo.com/) as the web framework for developing our API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the resulting package for our API looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`model-deployment/api/`](https://github.com/particle1331/model-deployment/tree/heroku/api)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "api/\n",
    "├── app/\n",
    "│   ├── schemas/\n",
    "│   │   ├── __init__.py\n",
    "│   │   ├── health.py\n",
    "│   │   └── predict.py\n",
    "│   ├── __init__.py\n",
    "│   ├── api.py\n",
    "│   ├── config.py\n",
    "│   └── main.py\n",
    "├── tests/\n",
    "│   ├── __init__.py\n",
    "│   ├── conftest.py\n",
    "│   └── test_api.py\n",
    "├── Procfile\n",
    "├── mypy.ini\n",
    "├── tox.ini\n",
    "├── requirements.py\n",
    "├── runtime.txt\n",
    "└── test_requirements.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have two requirements files `requirements.txt` which specifies versions of libraries used in running the API, and `test_requirements.txt` that contains versions of tools that we will during development, such as testing, linting, and type checking. The important thing to note here is that we include the regression model package in the main requirements file.\n",
    "\n",
    "```\n",
    "regression-model-template==0.1.0\n",
    "```\n",
    "\n",
    "Tests are stored in the `tests/` directory. The file `mypy.ini` contains configurations for type checking. And `tox.ini` file contains definitions of tox environments that we will be using, e.g. `run` for running the server in debug mode. Finally, the `Procfile` and `runtime.txt` are files needed when deploying later to Heroku.\n",
    "\n",
    "The main functionality of our API is contained in the `app/` folder. The `schemas/` folder contains the Pydantic models for data that will be passed into and out of the endpoints. Then, we have four modules: `__init__.py` contains the API's version, `api.py` which defines the API endpoints, `config.py` which handles configuration mostly about logging, and `main.py` combines everything together so that the API runs. Running the API can be conveniently done using tox:\n",
    "\n",
    "```\n",
    "$ tox -e run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uvicorn server should be running in `localhost:8001` after installing the necessary dependencies. Note that we get a warning for running the server in development mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "run run-test: commands[0] | python app/main.py\n",
    "2022-04-14 17:50:29.396 | WARNING  | __main__:<module>:55 - Running in development mode. Do not run like this in production.\n",
    "INFO:     Started server process [63671]\n",
    "2022-04-14 17:50:30.870 | INFO     | uvicorn.main:serve:405 - Started server process [63671]\n",
    "INFO:     Waiting for application startup.\n",
    "2022-04-14 17:50:30.870 | INFO     | uvicorn.lifespan.on:startup:22 - Waiting for application startup.\n",
    "INFO:     Application startup complete.\n",
    "2022-04-14 17:50:30.871 | INFO     | uvicorn.lifespan.on:startup:34 - Application startup complete.\n",
    "INFO:     Uvicorn running on http://localhost:8001 (Press CTRL+C to quit)\n",
    "2022-04-14 17:50:30.873 | INFO     | uvicorn.main:startup:492 - Uvicorn running on http://localhost:8001 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/localhost.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to `http://localhost:8001/docs` we can see the available endpoints. First we can try out `health` endpoint which should give us the JSON response:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"name\": \"House Price Prediction API\",\n",
    "  \"api_version\": \"0.0.1\",\n",
    "  \"model_version\": \"0.1.0\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the `predict` endpoint. Notice that it already has an example request body. Running this we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "  \"errors\": null,\n",
    "  \"version\": \"0.1.0\",\n",
    "  \"predictions\": [\n",
    "    113422.55344864173\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing `LotArea` from `11622` to `20000`, we observe no change. This is because this feature is not used by the model. If we change `GrLivArea` from `896` to `2000`, since this is a variable used by the linear model, we expect an increase in house price value. Indeed: \n",
    "\n",
    "```\n",
    "{\n",
    "  \"errors\": null,\n",
    "  \"version\": \"0.1.0\",\n",
    "  \"predictions\": [\n",
    "    143329.1612864663\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look at the main functionality of this part of our application. First, we will look at the schemas which models the responses of the endpoints. Then, we look at actual endpoints which will be serving the predictions as well as the API version. Finally, we look at logging and API settings, and how the final app is arranged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before looking at the endpoints, we look at the Pydantic models for responses of the API endpoints. First, the init file simply imports all the Pydantic models from the `health` and `predict` modules. For the `health` endpoint we have the health schema `Health` defined as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`app/schemas/health.py`](https://github.com/particle1331/model-deployment/tree/heroku/api/app/schemas/health.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Health(BaseModel):\n",
    "    name: str\n",
    "    api_version: str\n",
    "    model_version: str\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we have `MultipleHouseDataInputs`, and `PredictionResults`. Note that the structure of the latter two models are based on the corresponding schemas for validating the data for the machine learning model in the `regression_model` package. In fact, we explicitly import `HouseDataInputSchema` from the ML model package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`app/schemas/predict.py`](https://github.com/particle1331/model-deployment/tree/heroku/api/app/schemas/predict.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from typing import Any, List, Optional\n",
    "from pydantic import BaseModel\n",
    "from regression_model.processing.schemas import HouseDataInputSchema\n",
    "\n",
    "\n",
    "class PredictionResults(BaseModel):\n",
    "    errors: Optional[Any]\n",
    "    version: str\n",
    "    predictions: Optional[List[float]]\n",
    "\n",
    "\n",
    "class MultipleHouseDataInputs(BaseModel):\n",
    "    inputs: List[HouseDataInputSchema]\n",
    "\n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"inputs\": [\n",
    "                    {\n",
    "                        \"MSSubClass\": 20,\n",
    "                        \"MSZoning\": \"RH\",\n",
    "                        \"LotFrontage\": 80.0,\n",
    "                        ...\n",
    "                        \"YrSold\": 2010,\n",
    "                        \"SaleType\": \"WD\",\n",
    "                        \"SaleCondition\": \"Normal\",\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `MultipleHouseDataInputs` we supplement the original schema from `regression_model` by adding an example input which will be used in the automatic documentation. Recall that the expected result of the `make_prediction` function is a dictionary containing validation errors, the package version for generating the trained ML model, and the actual predictions. Refer to the [previous article](https://particle1331.github.io/inefficient-networks/notebooks/deployment/production-code.html) if these are all new to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at the models, let us check out the API endpoints. These are located in `api.py` where we see that there are two endpoints connected to `api_router`. This is then connected to the main app as we shall see later. Note that the pattern for defining endpoints includes setting the HTTP method (e.g. GET or POST), setting the endpoint URL (e.g. `\"/health\"`), the Pydantic model for the response, and the status code.\n",
    "First, we have the `health` endpoint with expected response that is a JSON object derived from the `Health` schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`app/api.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/app/api.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@api_router.get(\"/health\", response_model=schemas.Health, status_code=200)\n",
    "def health() -> dict:\n",
    "    \"\"\"Root GET.\"\"\"\n",
    "\n",
    "    health = schemas.Health(\n",
    "        name=settings.PROJECT_NAME, \n",
    "        api_version=__version__, \n",
    "        model_version=model_version\n",
    "    )\n",
    "\n",
    "    return health.dict()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this endpoint returns a dictionary but is converted to the appropriate response based on the `response_model` parameter in the endpoint decorator. The decorator also tells us that this is a GET request that results in a status code of `200 OK` if successful. Here `__version__` is the version of the API, `model_version` is the version of the ML model package, and `name` is the project name which we will see later in the `settings` object. Let's try to make a request using [HTTPie](https://httpie.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mHTTP\u001b[39;49;00m/\u001b[34m1.1\u001b[39;49;00m \u001b[34m200\u001b[39;49;00m \u001b[36mOK\u001b[39;49;00m\n",
      "\u001b[36mcontent-length\u001b[39;49;00m: 83\n",
      "\u001b[36mcontent-type\u001b[39;49;00m: application/json\n",
      "\u001b[36mdate\u001b[39;49;00m: Sat, 16 Apr 2022 00:43:57 GMT\n",
      "\u001b[36mserver\u001b[39;49;00m: uvicorn\n",
      "\n",
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"api_version\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"0.0.1\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"model_version\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"0.1.0\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"name\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"House Price Prediction API\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!http GET :8001/api/v1/health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict endpoint implements a POST async method that simply wraps our `make_prediction` function as an API endpoint. As discussed, the response uses the `PredictionResults` as a response model. Observe that we also have to specify a model for the request body, here `MultipleDataInputs` for `input_data`. \n",
    "\n",
    "Since the `make_prediction` function takes in a Pandas dataframe, we had to convert `input_data` to a dataframe. Notice also that we make logs in all important places: inputs and outputs at INFO level, and errors at WARNING level (if there are any). Note that this is not a proper async function since `make_prediction` is not implemented to process asynchronous I/O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`app/api.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/app/api.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@api_router.post(\"/predict\", response_model=schemas.PredictionResults, status_code=200)\n",
    "async def predict(input_data: schemas.MultipleHouseDataInputs) -> Any:\n",
    "    \"\"\"Make house price predictions with the regression model.\"\"\"\n",
    "\n",
    "    input_df = pd.DataFrame(jsonable_encoder(input_data.inputs))\n",
    "\n",
    "    # Advanced: You can improve performance of your API by rewriting the\n",
    "    # `make prediction` function to be async and using await here.\n",
    "    logger.info(f\"Making prediction on inputs: {input_data.inputs}\")\n",
    "    results = make_prediction(input_data=input_df.replace({np.nan: None}))\n",
    "\n",
    "    if results[\"errors\"] is not None:\n",
    "        logger.warning(f\"Prediction validation error: {results.get('errors')}\")\n",
    "        raise HTTPException(status_code=400, detail=json.loads(results[\"errors\"]))\n",
    "\n",
    "    logger.info(f\"Prediction results: {results.get('predictions')}\")\n",
    "\n",
    "    return results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that if there are errors, then we raise an `HTTPException` containing the errors as JSON with status code `400`. Testing this out, the API specifically tells us that we passed an invalid value to `\"MSSubClass\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mHTTP\u001b[39;49;00m/\u001b[34m1.1\u001b[39;49;00m \u001b[34m422\u001b[39;49;00m \u001b[36mUnprocessable Entity\u001b[39;49;00m\n",
      "\u001b[36mcontent-length\u001b[39;49;00m: 118\n",
      "\u001b[36mcontent-type\u001b[39;49;00m: application/json\n",
      "\u001b[36mdate\u001b[39;49;00m: Sat, 16 Apr 2022 00:43:58 GMT\n",
      "\u001b[36mserver\u001b[39;49;00m: uvicorn\n",
      "\n",
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"detail\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"loc\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m                \u001b[39;49;00m\u001b[33m\"body\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m                \u001b[39;49;00m\u001b[33m\"inputs\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m                \u001b[39;49;00m\u001b[34m0\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m                \u001b[39;49;00m\u001b[33m\"MSSubClass\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"msg\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"value is not a valid integer\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m            \u001b[39;49;00m\u001b[94m\"type\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"type_error.integer\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!http POST :8001/api/v1/predict <<< '{\"inputs\": [{\"MSSubClass\": \"A\",\"MSZoning\": \"RH\",\"LotFrontage\": 80,\"LotArea\": 11622,\"Street\": \"Pave\",\"LotShape\": \"Reg\",\"LandContour\": \"Lvl\",\"Utilities\": \"AllPub\",\"LotConfig\": \"Inside\",\"LandSlope\": \"Gtl\",\"Neighborhood\": \"NAmes\",\"Condition1\": \"Feedr\",\"Condition2\": \"Norm\",\"BldgType\": \"1Fam\",\"HouseStyle\": \"1Story\",\"OverallQual\": 5,\"OverallCond\": 6,\"YearBuilt\": 1961,\"YearRemodAdd\": 1961,\"RoofStyle\": \"Gable\",\"RoofMatl\": \"CompShg\",\"Exterior1st\": \"VinylSd\",\"Exterior2nd\": \"VinylSd\",\"MasVnrType\": \"None\",\"MasVnrArea\": 0,\"ExterQual\": \"TA\",\"ExterCond\": \"TA\",\"Foundation\": \"CBlock\",\"BsmtQual\": \"TA\",\"BsmtCond\": \"TA\",\"BsmtExposure\": \"No\",\"BsmtFinType1\": \"Rec\",\"BsmtFinSF1\": 468,\"BsmtFinType2\": \"LwQ\",\"BsmtFinSF2\": 144,\"BsmtUnfSF\": 270,\"TotalBsmtSF\": 882,\"Heating\": \"GasA\",\"HeatingQC\": \"TA\",\"CentralAir\": \"Y\",\"Electrical\": \"SBrkr\",\"FirstFlrSF\": 896,\"SecondFlrSF\": 0,\"LowQualFinSF\": 0,\"GrLivArea\": 896,\"BsmtFullBath\": 0,\"BsmtHalfBath\": 0,\"FullBath\": 1,\"HalfBath\": 0,\"BedroomAbvGr\": 2,\"KitchenAbvGr\": 1,\"KitchenQual\": \"TA\",\"TotRmsAbvGrd\": 5,\"Functional\": \"Typ\",\"Fireplaces\": 0,\"GarageType\": \"Attchd\",\"GarageYrBlt\": 1961,\"GarageFinish\": \"Unf\",\"GarageCars\": 1,\"GarageArea\": 730,\"GarageQual\": \"TA\",\"GarageCond\": \"TA\",\"PavedDrive\": \"Y\",\"WoodDeckSF\": 140,\"OpenPorchSF\": 0,\"EnclosedPorch\": 0,\"ThreeSsnPortch\": 0,\"ScreenPorch\": 120,\"PoolArea\": 0,\"Fence\": \"MnPrv\",\"MiscVal\": 0,\"MoSold\": 6,\"YrSold\": 2010,\"SaleType\": \"WD\",\"SaleCondition\": \"Normal\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that `\"MSSubclass\"` [expects an int](https://github.com/particle1331/model-deployment/tree/heroku/packages/regression_model/regression_model/processing/schemas.py#L57). But we can pass the string `\"20\"` and the `MultipleHouseDataInputs` model automatically converts this to an integer. This interaction between schemas and data for our endpoints makes FastAPI really nice to work with. Also see [dependency injections](https://fastapi.tiangolo.com/tutorial/dependencies/) which is a central feature of FastAPI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mHTTP\u001b[39;49;00m/\u001b[34m1.1\u001b[39;49;00m \u001b[34m200\u001b[39;49;00m \u001b[36mOK\u001b[39;49;00m\n",
      "\u001b[36mcontent-length\u001b[39;49;00m: 68\n",
      "\u001b[36mcontent-type\u001b[39;49;00m: application/json\n",
      "\u001b[36mdate\u001b[39;49;00m: Sat, 16 Apr 2022 00:43:58 GMT\n",
      "\u001b[36mserver\u001b[39;49;00m: uvicorn\n",
      "\n",
      "{\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"errors\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mnull\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"predictions\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m[\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m        \u001b[39;49;00m\u001b[34m113422.55344864173\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94m\"version\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"0.1.0\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "}\u001b[37m\u001b[39;49;00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!http POST :8001/api/v1/predict <<< '{\"inputs\": [{\"MSSubClass\": \"20\",\"MSZoning\": \"RH\",\"LotFrontage\": 80,\"LotArea\": 11622,\"Street\": \"Pave\",\"LotShape\": \"Reg\",\"LandContour\": \"Lvl\",\"Utilities\": \"AllPub\",\"LotConfig\": \"Inside\",\"LandSlope\": \"Gtl\",\"Neighborhood\": \"NAmes\",\"Condition1\": \"Feedr\",\"Condition2\": \"Norm\",\"BldgType\": \"1Fam\",\"HouseStyle\": \"1Story\",\"OverallQual\": 5,\"OverallCond\": 6,\"YearBuilt\": 1961,\"YearRemodAdd\": 1961,\"RoofStyle\": \"Gable\",\"RoofMatl\": \"CompShg\",\"Exterior1st\": \"VinylSd\",\"Exterior2nd\": \"VinylSd\",\"MasVnrType\": \"None\",\"MasVnrArea\": 0,\"ExterQual\": \"TA\",\"ExterCond\": \"TA\",\"Foundation\": \"CBlock\",\"BsmtQual\": \"TA\",\"BsmtCond\": \"TA\",\"BsmtExposure\": \"No\",\"BsmtFinType1\": \"Rec\",\"BsmtFinSF1\": 468,\"BsmtFinType2\": \"LwQ\",\"BsmtFinSF2\": 144,\"BsmtUnfSF\": 270,\"TotalBsmtSF\": 882,\"Heating\": \"GasA\",\"HeatingQC\": \"TA\",\"CentralAir\": \"Y\",\"Electrical\": \"SBrkr\",\"FirstFlrSF\": 896,\"SecondFlrSF\": 0,\"LowQualFinSF\": 0,\"GrLivArea\": 896,\"BsmtFullBath\": 0,\"BsmtHalfBath\": 0,\"FullBath\": 1,\"HalfBath\": 0,\"BedroomAbvGr\": 2,\"KitchenAbvGr\": 1,\"KitchenQual\": \"TA\",\"TotRmsAbvGrd\": 5,\"Functional\": \"Typ\",\"Fireplaces\": 0,\"GarageType\": \"Attchd\",\"GarageYrBlt\": 1961,\"GarageFinish\": \"Unf\",\"GarageCars\": 1,\"GarageArea\": 730,\"GarageQual\": \"TA\",\"GarageCond\": \"TA\",\"PavedDrive\": \"Y\",\"WoodDeckSF\": 140,\"OpenPorchSF\": 0,\"EnclosedPorch\": 0,\"ThreeSsnPortch\": 0,\"ScreenPorch\": 120,\"PoolArea\": 0,\"Fence\": \"MnPrv\",\"MiscVal\": 0,\"MoSold\": 6,\"YrSold\": 2010,\"SaleType\": \"WD\",\"SaleCondition\": \"Normal\"}]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we look at how the whole app ties together. Here we are looking at the `main` module. First, we define our FastAPI `app` object:\n",
    "\n",
    "```{margin}\n",
    "[`app/main.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/app/main.py)\n",
    "```\n",
    "\n",
    "```python\n",
    "app = FastAPI(\n",
    "    title=settings.PROJECT_NAME, \n",
    "    openapi_url=f\"{settings.API_V1_STR}/openapi.json\"\n",
    ")\n",
    "```\n",
    "\n",
    "The `openapi_url` simply provides the URL where we can view the [standard OpenAPI document](https://spec.openapis.org/oas/latest.html) for our API. Then, we assign `root_router = APIRouter()` and define on it an `index` GET endpoint:\n",
    "\n",
    "```{margin}\n",
    "[`app/main.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/app/main.py)\n",
    "```\n",
    "\n",
    "```python\n",
    "root_router = APIRouter()\n",
    "\n",
    "@root_router.get(\"/\", response_class=HTMLResponse)\n",
    "def index():\n",
    "    \"\"\"Basic HTML response.\"\"\"\n",
    "    \n",
    "    return (\n",
    "        \"<html>\"\n",
    "        \"<body style='padding: 10px;'>\"\n",
    "        \"<h1>Welcome to the API</h1>\"\n",
    "        \"<div>\"\n",
    "        \"Check the docs: <a href='/docs'>here</a>\"\n",
    "        \"</div>\"\n",
    "        \"</body>\"\n",
    "        \"</html>\"\n",
    "    )\n",
    "```\n",
    "\n",
    "This simply gives us the HTML welcome message which links to the automatic docs. Then, we import `api_router` from the `api` module where we defined all our API endpoints and connect it all into our application:\n",
    "\n",
    "```{margin}\n",
    "[`app/main.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/app/main.py)\n",
    "```\n",
    "\n",
    "```python\n",
    "app.include_router(api_router, prefix=settings.API_V1_STR)\n",
    "app.include_router(root_router)\n",
    "```\n",
    "\n",
    "Note that having a prefix means that we must prepend all URLs with `settings.API_V1_STR` which here is simply `\"/api/v1\"`. This is done as part of good software practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging is a critical aspect of deployed applications. Logs along with things like metrics allow us to observe our server. In particular, for servers that process a large number of requests, we might even perform data analysis on logs to understand what's happening to our server.\n",
    "\n",
    "Observe that in the `main` module, logging is set up as soon as possible by calling `setup_app_logging` on top of the file. This is defined in the `config` module as follows. Notice that this simply sets the logging level for the two standard server loggers `uvicorn.asgi` and `uvicorn.access` as well intercepting anything these loggers are capturing towards Loguru sinks. The sink and logging level for the Python logger from `loguru` are likewise configured thereafter. Logging level can be set in `LoggingSettings`, e.g. `logging.DEBUG` to get debug level messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`app/config.py`](https://github.com/particle1331/model-deployment/tree/heroku/api/app/config.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class LoggingSettings(BaseSettings):\n",
    "    LOGGING_LEVEL: int = logging.INFO  # logging levels are type int\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    API_V1_STR: str = \"/api/v1\"\n",
    "    PROJECT_NAME: str = \"House Price Prediction API\"\n",
    "    logging: LoggingSettings = LoggingSettings()\n",
    "\n",
    "    class Config:\n",
    "        case_sensitive = True\n",
    "\n",
    "\n",
    "class InterceptHandler(logging.Handler):\n",
    "    ...\n",
    "    # See: https://loguru.readthedocs.io/en/stable/overview.html#entirely-compatible-with-standard-logging  # noqa\n",
    "    # This will be used to incercept uvicorn loggers towards Loguru sinks. \n",
    "\n",
    "\n",
    "def setup_app_logging(config: Settings) -> None:\n",
    "    \"\"\"Prepare custom logging for our application.\"\"\"\n",
    "\n",
    "    LOGGERS = (\"uvicorn.asgi\", \"uvicorn.access\")\n",
    "    logging.getLogger().handlers = [InterceptHandler()]\n",
    "    for logger_name in LOGGERS:\n",
    "        logging_logger = logging.getLogger(logger_name)\n",
    "        logging_logger.handlers = [InterceptHandler(level=config.logging.LOGGING_LEVEL)]\n",
    "\n",
    "    logger.configure(\n",
    "        handlers=[{\"sink\": sys.stderr, \"level\": config.logging.LOGGING_LEVEL}]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will look at how to test our API using `pytest`. Note that our test suite consists of a single test of the `predict` endpoint. In the `conftest.py` module, we define two fixtures. The `test_data` fixture simply loads the test data included inside the `regression_model` package. Then we have the `client` fixture which contains `TestClient`. \n",
    "\n",
    "The idea is that to make a POST request on the client and check whether the response agrees with our expectations. This includes status code, the predictions, existence of errors and so on. Incidentally, observe that the example we used in the `predict` endpoint is the first instance in the test dataset. Note that the JSON payload for the test client must follow the input schema for the `predict` endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin}\n",
    "[`tests/test_api.py`](https://github.com/particle1331/model-deployment/blob/heroku/api/tests/test_api.py)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def test_make_prediction(client: TestClient, test_data: pd.DataFrame) -> None:\n",
    "    # Given\n",
    "    payload = {\n",
    "        # Ensure pydantic plays well with np.nan\n",
    "        \"inputs\": test_data.replace({np.nan: None}).to_dict(orient=\"records\")\n",
    "    }\n",
    "\n",
    "    # When\n",
    "    response = client.post(\n",
    "        \"http://localhost:8001/api/v1/predict\",\n",
    "        json=payload,\n",
    "    )\n",
    "\n",
    "    # Then\n",
    "    assert response.status_code == 200\n",
    "    prediction_data = response.json()\n",
    "    assert prediction_data[\"predictions\"]\n",
    "    assert prediction_data[\"errors\"] is None\n",
    "    assert math.isclose(prediction_data[\"predictions\"][0], 113422, rel_tol=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see where these tests come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
       "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
       "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
       "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
       "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
       "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
       "\n",
       "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       0      6    2010        WD         Normal  \n",
       "1   12500      6    2010        WD         Normal  \n",
       "2       0      3    2010        WD         Normal  \n",
       "3       0      6    2010        WD         Normal  \n",
       "4       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from regression_model.processing.data_manager import load_dataset\n",
    "from regression_model.predict import make_prediction\n",
    "from regression_model.config.core import config\n",
    "\n",
    "test_data = load_dataset(file_name=config.app_config.test_data_file)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly predicting on first column using the ML model, we see that we can check whether the prediction is within `100` of `113422.55344864173` for the first element of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [113422.55344864173], 'version': '0.1.0', 'errors': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict \n",
    "make_prediction(input_data=test_data.iloc[[0], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying to Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick deployment demo, we will be deploying our application to [Heroku](https://heroku.com). First, install the [Heroku CLI](https://devcenter.heroku.com/articles/heroku-cli), then run `heroku autocomplete` on the terminal. This will require login and registration. On the Heroku dashboard, we can create a new app. Note that our directory is a monorepo and we want only the `api` directory to be pushed to Heroku. This can be done by using the following command. Note that this also runs the web app as specified in the `Procfile` (also see the logs below).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ heroku git:remote -a guarded-mesa-83434 # app name\n",
    "$ git add .\n",
    "$ git commit -m \"Push API code to Heroku.\"\n",
    "$ git subtree push --prefix api heroku main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "git push using:  heroku main\n",
    "Enumerating objects: 6, done.\n",
    "Counting objects: 100% (6/6), done.\n",
    "Delta compression using up to 8 threads\n",
    "Compressing objects: 100% (4/4), done.\n",
    "Writing objects: 100% (4/4), 515 bytes | 515.00 KiB/s, done.\n",
    "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
    "remote: Compressing source files... done.\n",
    "remote: Building source:\n",
    "remote:\n",
    "remote: -----> Building on the Heroku-20 stack\n",
    "remote: -----> Using buildpack: heroku/python\n",
    "remote: -----> Python app detected\n",
    "remote: -----> Using Python version specified in runtime.txt\n",
    "remote:  !     Python has released a security update! Please consider upgrading to python-3.9.12\n",
    "remote:        Learn More: https://devcenter.heroku.com/articles/python-runtimes\n",
    "remote: -----> No change in requirements detected, installing from cache\n",
    "remote: -----> Using cached install of python-3.9.5\n",
    "remote: -----> Installing pip 22.0.4, setuptools 60.10.0 and wheel 0.37.1\n",
    "remote: -----> Installing SQLite3\n",
    "remote: -----> Installing requirements with pip\n",
    "remote: -----> Discovering process types\n",
    "remote:        Procfile declares types -> web\n",
    "remote:\n",
    "remote: -----> Compressing...\n",
    "remote:        Done: 211.7M\n",
    "remote: -----> Launching...\n",
    "remote:        Released v4\n",
    "remote:        https://guarded-mesa-83434.herokuapp.com/ deployed to Heroku\n",
    "remote:\n",
    "remote: Verifying deploy... done.\n",
    "To https://git.heroku.com/guarded-mesa-83434.git\n",
    "   83f66c4..ae9fd40  ae9fd40f58c9152fd540a4e1a87c86f66af66ea2 -> main\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This deploys our app on the internet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/deploy-to-heroku.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the health endpoint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../img/health-api.png\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have deployed our app, we can think of possible improvements. For example, we may want to automate deployment every time we make a push to the code repository. And what about publishing and versioning models that are not included inside a package? Though we have used tox to automate tests, it is not yet clear whether results of models are reproducible in the created virtual environments. Also, how can we move beyond Heroku to other service providers such as AWS? In the next articles, we will systematically improve things and make the app that we've developed here production ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a55a0d1272a360f93e747858d443ec26da69f69eac36db3e567a961ca624a861"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
